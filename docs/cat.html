<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 8 Categorical Predictors in MLR | Linear Models for Data Science</title>
<meta name="author" content="Jeffrey Woo">
<meta name="description" content="8.1 Introduction Thus far, we have only considered predictors that are quantitative in MLR. But what if we need or want to consider predictors that are categorical instead? For example, what if we...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Chapter 8 Categorical Predictors in MLR | Linear Models for Data Science">
<meta property="og:type" content="book">
<meta property="og:description" content="8.1 Introduction Thus far, we have only considered predictors that are quantitative in MLR. But what if we need or want to consider predictors that are categorical instead? For example, what if we...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 8 Categorical Predictors in MLR | Linear Models for Data Science">
<meta name="twitter:description" content="8.1 Introduction Thus far, we have only considered predictors that are quantitative in MLR. But what if we need or want to consider predictors that are categorical instead? For example, what if we...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Linear Models for Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">1</span> Data Wrangling with R</a></li>
<li><a class="" href="viz.html"><span class="header-section-number">2</span> Data Visualization with R Using ggplot2</a></li>
<li><a class="" href="slr.html"><span class="header-section-number">3</span> Basics with Simple Linear Regression (SLR)</a></li>
<li><a class="" href="inf.html"><span class="header-section-number">4</span> Inference with Simple Linear Regression (SLR)</a></li>
<li><a class="" href="diag.html"><span class="header-section-number">5</span> Model Diagnostics and Remedial Measures in SLR</a></li>
<li><a class="" href="mlr.html"><span class="header-section-number">6</span> Multiple Linear Regression (MLR)</a></li>
<li><a class="" href="genF.html"><span class="header-section-number">7</span> General Linear \(F\) Test and Multicollinearity</a></li>
<li><a class="active" href="cat.html"><span class="header-section-number">8</span> Categorical Predictors in MLR</a></li>
<li><a class="" href="crit.html"><span class="header-section-number">9</span> Model Selection Criteria and Automated Search Procedures</a></li>
<li><a class="" href="out.html"><span class="header-section-number">10</span> Analysis of Residuals in MLR</a></li>
<li><a class="" href="logistic1.html"><span class="header-section-number">11</span> Logistic Regression</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">12</span> Introduction</a></li>
<li><a class="" href="methods.html"><span class="header-section-number">13</span> Methods</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="cat" class="section level1" number="8">
<h1>
<span class="header-section-number">8</span> Categorical Predictors in MLR<a class="anchor" aria-label="anchor" href="#cat"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-7" class="section level2" number="8.1">
<h2>
<span class="header-section-number">8.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-7"><i class="fas fa-link"></i></a>
</h2>
<p>Thus far, we have only considered predictors that are quantitative in MLR. But what if we need or want to consider predictors that are categorical instead? For example, what if we wish to investigate the earnings of college graduates based on the type of major? The predictor variable, type of major, is clearly categorical and not quantitative. Categorical variables can be incorporated in MLR. In this module, you will learn how to use and interpret the MLR model when categorical predictors are present.</p>
<div id="quantitative-vs-categorical-variable" class="section level3" number="8.1.1">
<h3>
<span class="header-section-number">8.1.1</span> Quantitative vs categorical variable<a class="anchor" aria-label="anchor" href="#quantitative-vs-categorical-variable"><i class="fas fa-link"></i></a>
</h3>
<p>First, a quick review on variable types. Variables can be divided into two types: quantitative or categorical. A general way to assess the type of a variable is the answer to the following question: Do arithmetic operations on the variable make sense? If yes, the variable is quantitative.</p>
<div id="quantitative-variable" class="section level4" number="8.1.1.1">
<h4>
<span class="header-section-number">8.1.1.1</span> Quantitative variable<a class="anchor" aria-label="anchor" href="#quantitative-variable"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Quantitative variables</strong> are measured in terms of numbers, where the number represents an amount. Quantitative variables can be subdivided into either continuous or discrete.</p>
<ul>
<li>
<strong>Continuous</strong> quantitative variable: takes on any numerical value within a range. E.g.: height can be measured in terms of centimeters or inches. It is continuous as the value can take on any value between the shortest and tallest person.</li>
<li>
<strong>Discrete</strong> quantitative variable: takes on distinct numerical values. E.g. the number of failures among 10 experiments. It is discrete as it can only take on integers between 0 and 10.</li>
</ul>
<p>A question to determine if the variable is continuous or discrete: Can you potentially list all the plausible values of the variable? If yes, the variable is discrete. For the example above, we can list the plausible values for the number of failures among 10 experiments as: 0, 1, 2, all the way to 10. For the height variable, the list of numerical values for height will be an infinite list as height can take on an infinite number of decimal places.</p>
</div>
<div id="categorical-variables" class="section level4" number="8.1.1.2">
<h4>
<span class="header-section-number">8.1.1.2</span> Categorical variables<a class="anchor" aria-label="anchor" href="#categorical-variables"><i class="fas fa-link"></i></a>
</h4>
<p><strong>Categorical variables</strong> express qualitative attributes (often called qualitative variable). The <strong>levels</strong> (or classes) are the various attributes the variable can take on. For example, political affiliation is categorical with three levels: Democrat, Republican, Independent.</p>
<p>A <strong>binary variable</strong> is a categorical variable with two levels. For example, a variable on whether you voted during the 2020 presidential election is binary, as the answer is either yes or no.</p>
<p>The choice of methods used to analyze data are usually driven by whether the variables are quantitative or categorical. You might have noticed this when creating data visualizations: the visualization you use is driven by the type of variable. Discrete variables are interesting since we can use methods meant for quantitative or categorical variables. We will go over how to make this decision in the context of building MLR models later in the module.</p>
<p>We will see how to incorporate categorical predictors in MLR. We will first start with binary predictors before moving on to predictors with more than two levels.</p>
</div>
</div>
</div>
<div id="indicator-variables-and-dummy-coding" class="section level2" number="8.2">
<h2>
<span class="header-section-number">8.2</span> Indicator Variables and Dummy Coding<a class="anchor" aria-label="anchor" href="#indicator-variables-and-dummy-coding"><i class="fas fa-link"></i></a>
</h2>
<p>Let us start by considering this simple example: In a study of innovation in the insurance industry, an economist wishes to relate the speed with which an insurance innovation is
adopted (in months), <span class="math inline">\(y\)</span>, to the size of the firm, <span class="math inline">\(x_1\)</span>, and the type of firm (mutual or stock firms).</p>
<div class="sourceCode" id="cb297"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Data</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"insurance.txt"</span>, header<span class="op">=</span><span class="cn">FALSE</span>,sep<span class="op">=</span><span class="st">""</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/colnames.html">colnames</a></span><span class="op">(</span><span class="va">Data</span><span class="op">)</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"time"</span>,<span class="st">"size"</span>, <span class="st">"firm"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Data</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   time size   firm
## 1   17  151 mutual
## 2   26   92 mutual
## 3   21  175 mutual
## 4   30   31 mutual
## 5   22  104 mutual
## 6    0  277 mutual</code></pre>
<p>So we have one categorical variable, the type of firm, that is binary, as it has two levels, mutual or stock. We also have a quantitative predictor, the size of the firm, <span class="math inline">\(x_1\)</span>, and a quantitative response variable, the time to adopt an innovation.</p>
<div id="indicator-variables" class="section level3" number="8.2.1">
<h3>
<span class="header-section-number">8.2.1</span> Indicator variables<a class="anchor" aria-label="anchor" href="#indicator-variables"><i class="fas fa-link"></i></a>
</h3>
<p><strong>Indicator variables</strong> that take on the values 0 and 1 are commonly used to represent the levels of categorical predictors. For example, we may have the following two indicator variables to represent the two types of firms:</p>
<p><span class="math display">\[\begin{eqnarray*}
x_2 &amp;=&amp; \left\{ \begin{array}{ll} 1 &amp; \mbox{ if mutual firm} \\ 0 &amp;
\mbox{ otherwise;} \end{array}\right. \\
x_3 &amp;=&amp; \left\{ \begin{array}{ll} 1 &amp; \mbox{ if stock firm} \\ 0
&amp; \mbox{ otherwise;} \end{array} \right.
\end{eqnarray*}\]</span></p>
<p>and the MLR model is written as
<span class="math display">\[
y_i = \beta_0 + \beta_1x_{i1} + \beta_2x_{i2} + \beta_3x_{i3} +
\epsilon_i.
\]</span>
However, this will not work in MLR. Recall that the least squares estimators are</p>
<p><span class="math display" id="eq:8b">\[\begin{equation}
\boldsymbol{\hat{\beta}}   =
\left(\boldsymbol{X}^{\prime} \boldsymbol{X} \right)^{-1} \boldsymbol{X}^{\prime} \boldsymbol{y} .
\tag{8.1}
\end{equation}\]</span></p>
<p>The matrix <span class="math inline">\((\boldsymbol{X}^{\prime} \boldsymbol{X})\)</span> is not invertible if we use these indicator variables. Let us consider a toy example where <span class="math inline">\(n=4\)</span>, with the first two observations being mutual fims, and the last two observations being stock furms. The design matrix, <span class="math inline">\(\boldsymbol{X}\)</span>, becomes</p>
<p><span class="math display">\[
\left[
\begin{array}{cccc}
   1 &amp; x_{11} &amp; 1 &amp; 0   \\
   1 &amp; x_{21} &amp; 1 &amp; 0    \\
   1 &amp; x_{31} &amp; 0 &amp; 1   \\
   1 &amp; x_{41} &amp; 0 &amp; 1    \\
\end{array}
\right]
\]</span>
Notice that in the design matrix, column 1 equals to the sum of column 3 and column 4. This means we have linear dependence among the columns of the design matrix. And when this happens, <span class="math inline">\((\boldsymbol{X}^{\prime} \boldsymbol{X})^{-1}\)</span> cannot be found so unique solutions to the least squares estimators <a href="cat.html#eq:8b">(8.1)</a> do not exist.</p>
<p>To get around this issue, we use what is known as <strong>dummy coding</strong>.</p>
</div>
<div id="dummy-coding" class="section level3" number="8.2.2">
<h3>
<span class="header-section-number">8.2.2</span> Dummy coding<a class="anchor" aria-label="anchor" href="#dummy-coding"><i class="fas fa-link"></i></a>
</h3>
<p>We drop one of the indicator variables. In general, a categorical variable with <span class="math inline">\(a\)</span> levels will be represented by <span class="math inline">\(a-1\)</span> indicator variables, each taking on the values of 0 and 1. This method of coding categorical variables is called <strong>dummy coding</strong>. So for our example, since firm type is binary (two levels), we only need one indicator variable.</p>
<p>We can have the following model</p>
<p><span class="math display" id="eq:8additive">\[\begin{equation}
y = \beta_0 + \beta_1x_{1} + \beta_2I_{1} +
\epsilon,
\tag{8.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(x_1=\)</span> is the size of the firm and</p>
<p><span class="math display">\[\begin{eqnarray*}
I_1 &amp;=&amp; \left\{ \begin{array}{ll} 1 &amp; \mbox{ if stock firm} \\ 0 &amp;
\mbox{ otherwise.} \end{array}\right.
\end{eqnarray*}\]</span></p>
<p>So in this formulation, we only use one indicator variable, <span class="math inline">\(I_1\)</span>. Indicator variables are typically denoted by <span class="math inline">\(I\)</span>. In this formulation, mutual firm is coded 0, and stock firm is coded 1. The level that is coded 0 is called the <strong>reference</strong> class (sometimes called the baseline class). When the variable is binary, the choice for reference class is not important. The interpretation of the model does not change based on the choice for the reference class.</p>
</div>
<div id="regression-coefficient-interpretation" class="section level3" number="8.2.3">
<h3>
<span class="header-section-number">8.2.3</span> Regression coefficient interpretation<a class="anchor" aria-label="anchor" href="#regression-coefficient-interpretation"><i class="fas fa-link"></i></a>
</h3>
<p>To see how we can interpret the regression coefficients with dummy coding, we can substitute the numerical value of the indicator variable in <a href="cat.html#eq:8additive">(8.2)</a> to obtain the regression equation for each firm type:</p>
<ul>
<li><p>Mutual firms: <span class="math inline">\(E(y|x) = \beta_0 + \beta_1x_1 +\beta_2(0) = \beta_0 + \beta_1x_1\)</span></p></li>
<li><p>Stock firms: <span class="math inline">\(E(y|x) = \beta_0 + \beta_1x_1 + \beta_2(1) = (\beta_0+\beta_2) + \beta_1x_1\)</span></p></li>
</ul>
<p>We make the following observations:</p>
<ul>
<li>We have two straight lines, with the <strong>same</strong> slope <span class="math inline">\(\beta_1\)</span>, but the intercepts are <strong>different</strong>, <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_0 + \beta_2\)</span>. This formulation assumes the slope in the scatterplot of <span class="math inline">\(y\)</span> against <span class="math inline">\(x_1\)</span> is the same for both firm types.</li>
<li>
<span class="math inline">\(\beta_2\)</span> indicates the <strong>difference in the mean response for stock firms versus mutual firms (stock firms minus mutual firms), when controlling for size of firm.</strong>
</li>
</ul>
<p>In general, the coefficient of an indicator variable shows how much higher (or lower) the mean response is for the class coded 1 than the reference class, when controlling for <span class="math inline">\(x_1\)</span>.</p>
<p>Let us look at our example:</p>
<div class="sourceCode" id="cb299"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##convert categorical predictor to factor</span></span>
<span><span class="va">Data</span><span class="op">$</span><span class="va">firm</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">firm</span><span class="op">)</span></span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co">##scatterplot with separate regression lines</span></span>
<span><span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">size</span>, y<span class="op">=</span><span class="va">time</span>, color<span class="op">=</span><span class="va">firm</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="va">lm</span>, se<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Scatterplot of Time to Adopt Innovation against Assets, by Firm Type"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-209-1.png" width="672"></div>
<p>We create a scatterplot of the response variable against the quantitative predictor, with separate colors and lines for firm type. Notice that the lines are almost parallel. We noted earlier that the formulation assumes the slopes are parallel.</p>
<p><span class="math inline">\(\beta_1\)</span> denotes the slopes of both of these lines, and <span class="math inline">\(\beta_2\)</span> denotes how much higher the line is for stock firms than for mutual firms. Let us take a look at the estimated regression coefficients:</p>
<div class="sourceCode" id="cb300"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">time</span><span class="op">~</span><span class="va">size</span><span class="op">+</span><span class="va">firm</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = time ~ size + firm, data = Data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.6915 -1.7036 -0.4385  1.9210  6.3406 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 33.874069   1.813858  18.675 9.15e-13 ***
## size        -0.101742   0.008891 -11.443 2.07e-09 ***
## firmstock    8.055469   1.459106   5.521 3.74e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.221 on 17 degrees of freedom
## Multiple R-squared:  0.8951, Adjusted R-squared:  0.8827 
## F-statistic:  72.5 on 2 and 17 DF,  p-value: 4.765e-09</code></pre>
<p>Note the following from the output:</p>
<ul>
<li><p>We know that since the categorical predictor is binary, we should have only 1 indicator variable representing firm type.</p></li>
<li><p>In the output, note that we have one line for the categorical predictor, called <code>firmstock</code>. This tells us the name of the predictor, followed by the class that is coded 1. So this tells us that R coded stock firms as 1, and mutual firms as 0.</p></li>
<li><p>The estimated coefficient for <code>firmstock</code> is 8.055469. This means that the time to adopt innovation for stock firms is 8.055469 months longer than for mutual firms, when controlling for size of the firm. The associated p-value when testing this coefficient is small, so the data support claim that there is a significant difference in the mean time to adopt inoovation based on firm type, when controlling for size of firm. We do not drop firm type as a term in the model. Since the estimated coefficient is positive, the mean time to adopt innovation for stock firms is longer than for mutual firms, when controlling for size of firm.</p></li>
<li><p>The estimated coefficient for <code>size</code> is -0.101742. This means the time to adopt innovation decreases by 0.101742 months, per unit increase in firm size, for given firm type. The associated p-value when testing this coefficient is small, so we do not drop <code>size</code> as a term in the model.</p></li>
<li><p>The estimated regression equation is <span class="math inline">\(\hat{y} = 33.874069 - 0.101742 x_1 + 8.055469I_1\)</span>.</p></li>
<li><p>Estimated regression equation for mutual firms: <span class="math inline">\(\hat{y} = 33.874069 - 0.101742 x_1 + 8.055469(0) = 33.874 - 0.102 x_1\)</span>.</p></li>
<li><p>Estimated regression equation for stock firms: <span class="math inline">\(\hat{y} = 33.874069 - 0.101742 x_1 + 8.055469(1) = 41.930 - 0.102 x_1\)</span>.</p></li>
</ul>
</div>
<div id="thought-question" class="section level3" number="8.2.4">
<h3>
<span class="header-section-number">8.2.4</span> Thought question<a class="anchor" aria-label="anchor" href="#thought-question"><i class="fas fa-link"></i></a>
</h3>
<p>How will the output for this regression change if the dummy coding was changed, i.e. <span class="math inline">\(I_1 = 1\)</span> if mutual firm and 0 if stock firm?</p>
<p><em>Please view the associated video to review this question, as well as for more commentary on dummy coding.</em></p>
</div>
</div>
<div id="interaction-terms" class="section level2" number="8.3">
<h2>
<span class="header-section-number">8.3</span> Interaction Terms<a class="anchor" aria-label="anchor" href="#interaction-terms"><i class="fas fa-link"></i></a>
</h2>
<p>The regression model as stated in <a href="cat.html#eq:8additive">(8.2)</a> is sometimes called a model with <strong>additive effects</strong>. Additive effects assume that each predictor’s effect on the response does not depend on the value of the other predictor. As long as we hold the other predictor constant, changing the value of the predictor is associated with the same change in the mean response. Using our example, this implies that the when looking at the scatterplot of time to adopt innovation against size of firms, with separate lines for each firm type, the regression lines are parallel.</p>
<p>If the lines are not parallel, it means the effect of changing firm size on the time to adopt innovation depends on the firm type. When the effect of a predictor on the response depends on the value of the other predictor, we have an <strong>interaction effect</strong> between the predictors on the response variable. To add an interaction effect between the predictors into the model, we have</p>
<p><span class="math display" id="eq:8interaction">\[\begin{equation}
y = \beta_0 + \beta_1x_{1} + \beta_2I_1 + \beta_3 x_1 I_1 + \epsilon
\tag{8.3}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(I_1 = 1\)</span> if stock firm and 0 if mutual firm. Substituting the values for <span class="math inline">\(I_1\)</span> in <a href="cat.html#eq:8interaction">(8.3)</a>, we have the following regression equations for each firm type:</p>
<ul>
<li><p>Mutual firm: <span class="math inline">\(E(y|x) = \beta_0+\beta_2(0)+\beta_1x_1+\beta_3 x_1(0)=\beta_0+\beta_1x_1.\)</span></p></li>
<li><p>Stock firm: <span class="math inline">\(E(y|x) = \beta_0+\beta_2(1)+\beta_1x_1+\beta_3 x_1(1)=(\beta_0+\beta_2)+(\beta_1+\beta_3)x_1.\)</span></p></li>
</ul>
<p>We have different intercepts and different slopes for these regressions, whereas in model <a href="cat.html#eq:8additive">(8.2)</a>, the slopes are the same.</p>
<p>If there is an interaction, we can see the effect of changing <span class="math inline">\(x_1\)</span> on the response depends on the other predictor: for mutual firms, increasing <span class="math inline">\(x_1\)</span> by one unit changes the mean response by <span class="math inline">\(\beta_1\)</span>; while for tool stock firms, increasing <span class="math inline">\(x_1\)</span> by one unit changes the mean response by <span class="math inline">\(\beta_1 + \beta_3\)</span>.</p>
<p>Models with interactions are a bit more difficult to interpret than models with no interactions. Therefore, we typical assess if the interaction term is significant or not. This can be tested in a general linear <span class="math inline">\(F\)</span> test framework, since a model with additive effects <a href="cat.html#eq:8additive">(8.2)</a> is the reduced model and a model with interaction effects <a href="cat.html#eq:8interaction">(8.3)</a> is the full model. If the coefficient of the interaction term is insignificant, we can drop the interaction term and go with the model with just additive effects.</p>
<div class="sourceCode" id="cb302"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##model with interaction</span></span>
<span><span class="va">result.int</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">time</span><span class="op">~</span><span class="va">size</span><span class="op">*</span><span class="va">firm</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">result.int</span><span class="op">)</span> <span class="co">##can drop interaction</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = time ~ size * firm, data = Data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -5.7144 -1.7064 -0.4557  1.9311  6.3259 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    33.8383695  2.4406498  13.864 2.47e-10 ***
## size           -0.1015306  0.0130525  -7.779 7.97e-07 ***
## firmstock       8.1312501  3.6540517   2.225   0.0408 *  
## size:firmstock -0.0004171  0.0183312  -0.023   0.9821    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.32 on 16 degrees of freedom
## Multiple R-squared:  0.8951, Adjusted R-squared:  0.8754 
## F-statistic: 45.49 on 3 and 16 DF,  p-value: 4.675e-08</code></pre>
<div class="sourceCode" id="cb304"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##can also do general linear F test. same as t test since only dropping one term</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">result</span>,<span class="va">result.int</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: time ~ size + firm
## Model 2: time ~ size * firm
##   Res.Df    RSS Df Sum of Sq     F Pr(&gt;F)
## 1     17 176.39                          
## 2     16 176.38  1 0.0057084 5e-04 0.9821</code></pre>
<p>We look at the result of the <span class="math inline">\(t\)</span> test for the line <code>size:firmstock</code>, which is the way R denotes the interaction term <span class="math inline">\(x_1 I_1\)</span>. This test is insignificant, we do not have evidence that there is an interaction effect between size of firm and firm type. So we can drop the interaction and go with the simpler model with just additive effects. This is expected given that we have seen almost parallel slopes in the scatterplot.</p>
<p>Note that the <strong>hierarchical principle</strong> applies if we have an interaction term: if the interaction term is significant, the lower ordered terms must remain.</p>
<div id="consideration-of-interaction-terms" class="section level3" number="8.3.1">
<h3>
<span class="header-section-number">8.3.1</span> Consideration of interaction terms<a class="anchor" aria-label="anchor" href="#consideration-of-interaction-terms"><i class="fas fa-link"></i></a>
</h3>
<p>Typically, people start with an additive order model. Interactions considered at the start if:</p>
<ul>
<li>Exploring interactions is part of your research question.</li>
<li>An interaction makes sense contextually, or is well-established in the literature.</li>
<li>We have evidence of interaction based on visualizations.</li>
</ul>
</div>
<div id="interaction-vs-correlation" class="section level3" number="8.3.2">
<h3>
<span class="header-section-number">8.3.2</span> Interaction vs correlation<a class="anchor" aria-label="anchor" href="#interaction-vs-correlation"><i class="fas fa-link"></i></a>
</h3>
<p>A question that I often get from students have is “Aren’t variables that interact also correlated?” The short answer is no, as interaction and correlation are two very different concepts.</p>
<p>A short explanation is that if we say that there is an interaction between two variables, <span class="math inline">\(x_1, x_2\)</span>, it means how each predictor impacts the response variable <span class="math inline">\(y\)</span> depends on the value of the other predictor. Notice that there are three variables, <span class="math inline">\(y, x_1, x_2\)</span> needed when we talk about an interaction between <span class="math inline">\(x_1, x_2\)</span>.</p>
<p>Correlation only involves two variables.</p>
<p>For a more detailed explanation, including examples, please <a href="https://www.theanalysisfactor.com/interaction-association">read this page.</a></p>
</div>
<div id="dummy-coding-vs-separate-regressions" class="section level3" number="8.3.3">
<h3>
<span class="header-section-number">8.3.3</span> Dummy coding vs separate regressions<a class="anchor" aria-label="anchor" href="#dummy-coding-vs-separate-regressions"><i class="fas fa-link"></i></a>
</h3>
<p>A reasonable question that is often raised is: Why did we not carry out two separate regressions, one for each firm type? When using dummy coding, we are using one regression. The main reason is that it turns out that using one model with dummy coding leads to more precise estimates (smaller standard errors), than creating separate regression for each level. This is true as long as the regression assumptions are met, specifically that the variance of the errors is constant for both levels.</p>
</div>
</div>
<div id="beyond-binary-predictors" class="section level2" number="8.4">
<h2>
<span class="header-section-number">8.4</span> Beyond Binary Predictors<a class="anchor" aria-label="anchor" href="#beyond-binary-predictors"><i class="fas fa-link"></i></a>
</h2>
<p>If we have a categorical predictor with more than two levels, dummy coding is still used in the same manner: a categorical predictor with <span class="math inline">\(a\)</span> levels will be represented by <span class="math inline">\(a-1\)</span> indicator variables, each taking on the values of 0 and 1.</p>
<p>Let us use another example. In this example, we consider ratings of wines from California. The response variable is average quality rating, <span class="math inline">\(y\)</span>, with predictors average flavor rating, <span class="math inline">\(x_1\)</span>, and Region indicating which of three regions in California the wine is produced in. The regions are North, Central, and Napa Valley.</p>
<p>A few notes about using dummy coding in this example:</p>
<ul>
<li>Since region has three levels, we will have 2 indicator variables, with one class being the reference class.</li>
<li>The choice of reference class can be arbitrary, or if there is one class that you are most interested in, make that the reference class.</li>
<li>The interpretations of the regression model will be consistent regardless of choice for reference class.</li>
<li>If fitting a model with no interactions, the coefficient of each indicator variable denotes <strong>the difference in the mean response between the level that is coded 1 versus the reference class</strong>, while controlling for the other predictor.</li>
</ul>
<p>Let us create a scatterplot of quality rating against flavor rating, split by region:</p>
<div class="sourceCode" id="cb306"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##clear environment to start new example</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/rm.html">rm</a></span><span class="op">(</span>list<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/ls.html">ls</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">Data</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"wine.txt"</span>, header<span class="op">=</span><span class="cn">TRUE</span>, sep<span class="op">=</span><span class="st">""</span><span class="op">)</span></span>
<span><span class="co">##convert Region to factor</span></span>
<span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span> </span>
<span><span class="co">##assign descriptive labels for each region</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"North"</span>, <span class="st">"Central"</span>, <span class="st">"Napa"</span><span class="op">)</span> </span>
<span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="co">##scatterplot of Quality against Flavor, </span></span>
<span><span class="co">##separated by Region</span></span>
<span><span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Flavor</span>, y<span class="op">=</span><span class="va">Quality</span>, color<span class="op">=</span><span class="va">Region</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="va">lm</span>, se<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Scatterplot of Wine Quality against Flavor, by Region"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-212-1.png" width="672"></div>
<p>The regression equations are almost parallel so we consider a model with no interactions first. We can use the following indicator variables. Note that there are other ways to define them.</p>
<!-- eqnarray environment issue -->
<p>Since Napa Valley is California’s most famous wine region, we would like to make easy comparisons of other regressions with Napa Valley. So it makes sense to make Napa Valley the reference class.</p>
<p>The corresponding model with just additive effects would be</p>
<p><span class="math display">\[\begin{equation*}
y_i = \beta_0 + \beta_1x_{i1} + \beta_2I_{i1} + \beta_3I_{i2} +  \epsilon_i
\end{equation*}\]</span></p>
<p>So the regression functions are:</p>
<ul>
<li><p>North: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(1) + \beta_3(0) = (\beta_0+\beta_2) + \beta_1x_1\)</span></p></li>
<li><p>Central: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(0) + \beta_3(1) = (\beta_0+\beta_3) + \beta_1x_1\)</span></p></li>
<li><p>Napa Valley: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(0) + \beta_3(0) = \beta_0 + \beta_1x_1\)</span></p></li>
</ul>
<p>Recall that this model assumes the slopes are the same for all three regions. <span class="math inline">\(\beta_{2}\)</span>, <span class="math inline">\(\beta_{3}\)</span> indicate how different the mean ratings are for the North and Central regions compared with Napa Valley, respectively, when controlling for the other predictor, the average flavor rating.</p>
<p>Let us fit this model and look at the output:</p>
<div class="sourceCode" id="cb307"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##fit regression with no interaction</span></span>
<span><span class="va">reduced</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Quality</span><span class="op">~</span><span class="va">Flavor</span><span class="op">+</span><span class="va">Region</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Quality ~ Flavor + Region, data = Data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.97630 -0.58844  0.02184  0.51572  1.94232 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     8.3177     1.0100   8.235 1.31e-09 ***
## Flavor          1.1155     0.1738   6.417 2.49e-07 ***
## RegionNorth    -1.2234     0.4003  -3.056  0.00435 ** 
## RegionCentral  -2.7569     0.4495  -6.134 5.78e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.8946 on 34 degrees of freedom
## Multiple R-squared:  0.8242, Adjusted R-squared:  0.8087 
## F-statistic: 53.13 on 3 and 34 DF,  p-value: 6.358e-13</code></pre>
<p>Some observations from the output:</p>
<ul>
<li><p><span class="math inline">\(\hat{\beta_2}\)</span> is the estimated coefficient for the indicator of the North region. This value is -1.2234. We interpret this as the average quality rating for wines in the North region is 1.2234 lower than wines in the Napa Valley, when controlling for flavor rating.</p></li>
<li><p><span class="math inline">\(\hat{\beta_3}\)</span> is the estimated coefficient for the indicator of the Central region.The average quality rating for wines in the South region is 2.7569 lower than wines in the Napa Valley, when controlling for flavor rating.</p></li>
<li><p>As mentioned earlier, we can easily make comparisons for any level with the reference class.</p></li>
</ul>
<div id="difference-in-mean-response-between-levels-excluding-the-reference-class" class="section level3" number="8.4.1">
<h3>
<span class="header-section-number">8.4.1</span> Difference in mean response between levels excluding the reference class<a class="anchor" aria-label="anchor" href="#difference-in-mean-response-between-levels-excluding-the-reference-class"><i class="fas fa-link"></i></a>
</h3>
<p>Estimating the difference in the mean response between levels excluding the reference class can be done by estimating the difference between the regression coefficients of their respective indicator variables. In this example, <span class="math inline">\(\beta_2 - \beta_3\)</span> measures the difference in mean response between the North and Central regions, for given average flavor rating. The output from our model does not give us this difference immediately. We can either construct a confidence interval (CI) for <span class="math inline">\(\beta_2 - \beta_3\)</span>, or perform a hypothesis test for <span class="math inline">\(\beta_2 - \beta_3\)</span>.</p>
<div id="ci" class="section level4" number="8.4.1.1">
<h4>
<span class="header-section-number">8.4.1.1</span> CI<a class="anchor" aria-label="anchor" href="#ci"><i class="fas fa-link"></i></a>
</h4>
<p>A <span class="math inline">\(100(1-\alpha)\%\)</span> confidence interval of estimating the
differential effects between these regions will be
<span class="math display" id="eq:8CI">\[\begin{equation}
(\hat{\beta}_2-\hat{\beta}_3) \pm
t_{1-\alpha/2,n-p}se\left(\hat{\beta}_2-\hat{\beta}_3\right),
\tag{8.4}
\end{equation}\]</span></p>
<p>where</p>
<p><span class="math display">\[
Var\left(\hat{\beta}_2-\hat{\beta}_3\right) = Var\left(\hat{\beta}_2\right) + Var\left(\hat{\beta}_3\right) - 2 Cov(\hat{\beta}_2, \hat{\beta}_3).
\]</span></p>
<p>Note that in general, the variance for the difference in estimated coefficients is</p>
<p><span class="math display" id="eq:8diff">\[\begin{equation}
Var\left(\hat{\beta}_j-\hat{\beta}_l\right) = Var\left(\hat{\beta}_j\right) + Var\left(\hat{\beta}_l\right) - 2 Cov(\hat{\beta}_j, \hat{\beta}_l).
\tag{8.5}
\end{equation}\]</span></p>
<p>We need to obtain the variance-covariance matrix of the estimated coefficients:</p>
<div class="sourceCode" id="cb309"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##variance covariance matrix of estimated coefficients</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span>,<span class="fl">3</span><span class="op">)</span> <span class="co">##display 3 dp</span></span></code></pre></div>
<pre><code>##               (Intercept) Flavor RegionNorth RegionCentral
## (Intercept)         1.020 -0.170      -0.277        -0.277
## Flavor             -0.170  0.030       0.037         0.037
## RegionNorth        -0.277  0.037       0.160         0.113
## RegionCentral      -0.277  0.037       0.113         0.202</code></pre>
<p>Let us compute the CI for <span class="math inline">\(\beta_2 - \beta_3\)</span> using <a href="cat.html#eq:8CI">(8.4)</a></p>
<p><span class="math display">\[\begin{eqnarray*}
(\hat{\beta}_2-\hat{\beta}_3) &amp;\pm&amp;
t_{1-\alpha/2,n-p}\sqrt{Var\left(\hat{\beta}_2-\hat{\beta}_3\right)} \nonumber \\
(-1.2234 + 2.7569) &amp;\pm&amp; 2.032245 \sqrt{0.160 + 0.202 - 2 \times 0.113} \nonumber \\
(0.7840453&amp;,&amp; 2.2829547) \nonumber
\end{eqnarray*}\]</span></p>
<p>Note <span class="math inline">\(t_{1-\alpha/2,n-p}\)</span> found using <code>qt(0.975, 38-4)</code>.</p>
<p>The CI excludes 0, so there is a significant difference in the mean quality ratings for wines in the North and Central region, when controlling for flavor rating. The CI consists entirely of positive numbers, so the mean quality rating is higher for wines in the North region than the Central region, when controlling for flavor rating.</p>
<p><em>View the associated video for more in depth explanation for constructing this CI.</em></p>
</div>
<div id="hypothesis-test" class="section level4" number="8.4.1.2">
<h4>
<span class="header-section-number">8.4.1.2</span> Hypothesis test<a class="anchor" aria-label="anchor" href="#hypothesis-test"><i class="fas fa-link"></i></a>
</h4>
<p>We can also compare between the North and Central regions using hypothesis testing. The hypothesis statements will be:</p>
<p><span class="math display">\[
H_0: \beta_2 - \beta_3 = 0, H_a: \beta_2 - \beta_3 \neq 0.
\]</span></p>
<p>The <span class="math inline">\(t\)</span> statistic is</p>
<p><span class="math display">\[\begin{eqnarray*}
t &amp;=&amp; \frac{\hat{\beta}_2 - \hat{\beta}_3}{se\left(\hat{\beta}_2-\hat{\beta}_3\right)}\nonumber \\
  &amp;=&amp; \frac{-1.2234 + 2.7569}{\sqrt{0.160 + 0.202 - 2 \times 0.113}} \nonumber \\
  &amp;=&amp; 4.158286,
\end{eqnarray*}\]</span></p>
<p>which is larger than the critical value <code>qt(1-0.05/2, 38 - 4)</code> = 2.032245. So we reject the null hypothesis. Data support the claim that there is a significant difference in the mean quality ratings between wines from the North region and the Central region, when controlling for flavor rating.</p>
</div>
</div>
<div id="interactions" class="section level3" number="8.4.2">
<h3>
<span class="header-section-number">8.4.2</span> Interactions<a class="anchor" aria-label="anchor" href="#interactions"><i class="fas fa-link"></i></a>
</h3>
<p>Suppose we decide to assess if there is an interaction between flavor rating and region. In other words, the effect of flavor rating on quality rating differs by region. From the scatterplot, the slopes are not exactly parallel, so a significant interaction may exist. The model with interaction would be</p>
<p><span class="math display">\[\begin{equation*}
y = \beta_0 + \beta_1x_{1} + \beta_2I_{1} + \beta_3I_{2} + \beta_4 x_1 I_{1} + \beta_5 x_1 I_{2} + \epsilon_i
\end{equation*}\]</span></p>
<p>So regression functions are:</p>
<ul>
<li><p>North: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(1) + \beta_3(0) + \beta_4x_1(1) + \beta_5x_1(0) = (\beta_0+\beta_2) + (\beta_1 + \beta_4)x_1\)</span></p></li>
<li><p>Central: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(0) + \beta_3(1) + \beta_4x_1(0) + \beta_5x_1(1) = (\beta_0+\beta_3) + (\beta_1 + \beta_5)x_1\)</span></p></li>
<li><p>Napa Valley: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1 + \beta_2(0) + \beta_3(0) + \beta_4x_1(0) + \beta_5x_1(0) =\beta_0 + \beta_1x_1\)</span></p></li>
</ul>
<p>Let us perform a general linear <span class="math inline">\(F\)</span> test to see if we should use the model with no interactions or the model with interactions:</p>
<div class="sourceCode" id="cb311"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##consider model with interactions </span></span>
<span><span class="co">##(when slopes are not parallel)</span></span>
<span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Quality</span><span class="op">~</span><span class="va">Flavor</span><span class="op">*</span><span class="va">Region</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span></span>
<span><span class="co">##general linear F test for interaction terms</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">reduced</span>,<span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Quality ~ Flavor + Region
## Model 2: Quality ~ Flavor * Region
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     34 27.213                           
## 2     32 25.429  2    1.7845 1.1229 0.3378</code></pre>
<p>The general linear <span class="math inline">\(F\)</span> test is insignificant, so we use the reduced model, i.e. the model with no interactions.</p>
</div>
</div>
<div id="pairwise-comparisons" class="section level2" number="8.5">
<h2>
<span class="header-section-number">8.5</span> Pairwise Comparisons<a class="anchor" aria-label="anchor" href="#pairwise-comparisons"><i class="fas fa-link"></i></a>
</h2>
<p>When we have a categorical predictor, we may interested in making comparisons of the mean response between multiple pairs of levels within the categorical predictor. Going back to our wine example, we have a categorical predictor with three levels. This means we can make <span class="math inline">\(\binom{3}{2} = 3\)</span> pairwise comparisons:</p>
<ul>
<li>North region vs Napa Valley</li>
<li>Central region vs Napa Valley</li>
<li>North region vs Central region</li>
</ul>
<p>Based on our indicator variables, the regressions equations</p>
<ul>
<li><p>North: <span class="math inline">\(\mbox{E}\{Y\} = (\beta_0+\beta_2) + \beta_1x_1\)</span></p></li>
<li><p>Central: <span class="math inline">\(\mbox{E}\{Y\} = (\beta_0+\beta_3) + \beta_1x_1\)</span></p></li>
<li><p>Napa Valley: <span class="math inline">\(\mbox{E}\{Y\} = \beta_0 + \beta_1x_1\)</span></p></li>
</ul>
<p>So the parameters denoting the <strong>pairwise comparisons</strong> are</p>
<ul>
<li>
<span class="math inline">\(\beta_2\)</span>: North region vs Napa Valley</li>
<li>
<span class="math inline">\(\beta_3\)</span>: Central region vs Napa Valley</li>
<li>
<span class="math inline">\(\beta_2 - \beta_3\)</span>: North region vs Central region</li>
</ul>
<p>To assess whether there is a significant difference in the mean response between each pair, we can either:</p>
<ol style="list-style-type: decimal">
<li>
<p>Conduct 3 hypothesis tests:</p>
<ul>
<li><span class="math inline">\(H_0: \beta_2 = 0, H_a: \beta_2 \neq 0\)</span></li>
<li><span class="math inline">\(H_0: \beta_3 = 0, H_a: \beta_2 \neq 0\)</span></li>
<li><span class="math inline">\(H_0: \beta_3 - \beta_2 = 0, H_a: \beta_3 - \beta_2 \neq 0\)</span></li>
</ul>
</li>
</ol>
<p>or</p>
<ol start="2" style="list-style-type: decimal">
<li>
<p>Construct 3 confidence intervals:</p>
<ul>
<li><span class="math inline">\(\hat{\beta}_2 \pm t_{1- \alpha/2, n-p} se\left( \hat{\beta}_2 \right)\)</span></li>
<li><span class="math inline">\(\hat{\beta}_3 \pm t_{1- \alpha/2, n-p} se\left( \hat{\beta}_3 \right)\)</span></li>
<li><span class="math inline">\((\hat{\beta}_2 - \hat{\beta}_3) \pm t_{1- \alpha/2, n-p} se\left(\hat{\beta}_2 - \hat{\beta}_3 \right)\)</span></li>
</ul>
</li>
</ol>
<p>We have to be careful when conducting multiple tests or constructing multiple CIs.</p>
<div id="significance-level" class="section level3" number="8.5.1">
<h3>
<span class="header-section-number">8.5.1</span> Significance level<a class="anchor" aria-label="anchor" href="#significance-level"><i class="fas fa-link"></i></a>
</h3>
<p>The <strong>significance level</strong>, <span class="math inline">\(\alpha\)</span>, of a hypothesis test is the probability of wrongly rejecting <span class="math inline">\(H_0\)</span> if it is true. A <strong>Type I</strong> error is defined as wrongly rejecting the null hypothesis if it is true. So an alternate definition of the significance level is the probability of making a Type I error, if the null hypothesis is true.</p>
<p>Suppose we conduct the three hypothesis tests to compare all three pairs of regions, each at significance level <span class="math inline">\(\alpha\)</span>. If the null hypothesis is true for all 3 tests (i.e. there is no significant different in mean response between regions, when controlling for flavor), then the probability of making the right conclusions for all of the tests, assuming the tests are independent, will be <span class="math inline">\((1-\alpha)^3\)</span>. If <span class="math inline">\(\alpha=0.05\)</span>, this probability is <span class="math inline">\(0.95^3 = 0.857375\)</span>, not 0.95. A couple of things to consider:</p>
<ul>
<li>As we perform more hypothesis tests, the probability of making the right conclusions for all (assuming the null is true for all), decreases.</li>
<li>Can we do something so that the probability of not making at least one Type I error is still at least <span class="math inline">\(1-\alpha\)</span>?</li>
<li>For confidence intervals, we want to ensure that the confidence we have that the entire set of intervals capture the true values of the parameters is still at least <span class="math inline">\(1-\alpha\)</span>.</li>
</ul>
</div>
<div id="multiple-pairwise-comparisons" class="section level3" number="8.5.2">
<h3>
<span class="header-section-number">8.5.2</span> Multiple pairwise comparisons<a class="anchor" aria-label="anchor" href="#multiple-pairwise-comparisons"><i class="fas fa-link"></i></a>
</h3>
<p>To account for the fact that we are making multiple pairwise comparisons, we will need to make our confidence intervals wider, and the critical value larger to ensure the chance of making any Type I error is not more than <span class="math inline">\(\alpha\)</span>. There are a few procedures to do this. We will look two common procedures:</p>
<ul>
<li>Bonferroni procedure</li>
<li>Tukey procedure</li>
</ul>
<p>With the various procedures in multiple comparison:</p>
<ol style="list-style-type: decimal">
<li>All the confidence intervals take the form</li>
</ol>
<p><span class="math display" id="eq:8CImult">\[\begin{equation}
\text{estimate } \pm \text{ multiplier } \times \text{se(estimate) }.
\tag{8.6}
\end{equation}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>For hypothesis tests, we reject the null hypothesis when</li>
</ol>
<p><span class="math display" id="eq:8testmult">\[\begin{equation}
\text{test statistic } &gt; \text{ critical value}.
\tag{8.7}
\end{equation}\]</span></p>
<p>Only the multiplier and critical values change.</p>
</div>
<div id="bonferroni-procedure" class="section level3" number="8.5.3">
<h3>
<span class="header-section-number">8.5.3</span> Bonferroni procedure<a class="anchor" aria-label="anchor" href="#bonferroni-procedure"><i class="fas fa-link"></i></a>
</h3>
<p>Let <span class="math inline">\(g\)</span> denote the number of CIs we wish to construct, or the number of hypothesis tests we need to do to perform our pairwise comparisons.</p>
<div id="cis" class="section level4" number="8.5.3.1">
<h4>
<span class="header-section-number">8.5.3.1</span> CIs<a class="anchor" aria-label="anchor" href="#cis"><i class="fas fa-link"></i></a>
</h4>
<p>The Bonferroni procedure to ensure that we have at least <span class="math inline">\((1-\alpha)100\%\)</span> confidence that all the <span class="math inline">\(g\)</span> CIs capture the true value is</p>
<p><span class="math display" id="eq:8bon">\[\begin{equation}
\hat{\beta}_j \pm t_{1-\alpha/(2g); n-p} se(\hat{\beta}_j).
\tag{8.8}
\end{equation}\]</span></p>
<p>The multiplier in <a href="cat.html#eq:8bon">(8.8)</a> is found using <span class="math inline">\(t_{1-\alpha/(2g); n-p}\)</span> instead of <span class="math inline">\(t_{1-\alpha/2; n-p}\)</span>.</p>
<p>Going back to the wine example, suppose we wish to make all three pairwise comparisons. The CI to compare the North region with Napa Valley is</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{\beta}_2 &amp;\pm&amp; t_{1-\alpha/(2\times3); 38-4} se(\hat{\beta}_2) \nonumber \\
-1.2234 &amp;\pm&amp; 2.518259 \times 0.4003 \nonumber \\
(-2.2314592 &amp;,&amp; -0.2153408). \nonumber
\end{eqnarray*}\]</span></p>
<p>The CI to compare the Central region with Napa Valley is</p>
<p><span class="math display">\[\begin{eqnarray*}
\hat{\beta}_3 &amp;\pm&amp; t_{1-\alpha/(2\times3); 38-4} se(\hat{\beta}_3) \nonumber \\
-2.7569 &amp;\pm&amp; 2.518259 \times 0.4495 \nonumber \\
(-3.888858 &amp;,&amp; -1.624942). \nonumber
\end{eqnarray*}\]</span></p>
<p>The CI to compare the North region with the Central region is</p>
<p><span class="math display">\[\begin{eqnarray*}
(\hat{\beta}_2-\hat{\beta}_3) &amp;\pm&amp;
t_{1-\alpha/(2\times3); 38-4}\sqrt{Var\left(\hat{\beta}_2-\hat{\beta}_3\right)} \nonumber \\
(-1.2234 + 2.7569) &amp;\pm&amp; 2.518259 \sqrt{0.160 + 0.202 - 2 \times 0.113} \nonumber \\
(0.6048119&amp;,&amp; 2.4621881) \nonumber
\end{eqnarray*}\]</span></p>
<p>All three CIs exclude 0, so there is a significant difference in mean quality rating of wines between all pairs of regions, when controlling for flavor rating.</p>
</div>
<div id="hypothesis-tests" class="section level4" number="8.5.3.2">
<h4>
<span class="header-section-number">8.5.3.2</span> Hypothesis tests<a class="anchor" aria-label="anchor" href="#hypothesis-tests"><i class="fas fa-link"></i></a>
</h4>
<p>The critical value, based on the Bonferroni procedure, is <span class="math inline">\(t_{1-\alpha/(2g); n-p}\)</span> (instead of <span class="math inline">\(t_{1-\alpha/2; n-p}\)</span>). The test statistic still takes the form</p>
<p><span class="math display">\[
t = \frac{\text{estimate}}{s.e. \text{ of estimate}}.
\]</span></p>
<p>To compare the North region with Napa Valley, we have <span class="math inline">\(H_0: \beta_2 = 0, H_a: \beta_2 \neq 0\)</span>. The test statistic is</p>
<p><span class="math display">\[\begin{eqnarray*}
t &amp;=&amp; \frac{\hat{\beta}_2}{se(\hat{\beta}_2)} \nonumber \\
  &amp;=&amp; \frac{-1.2234}{0.4003} \nonumber \\
  &amp;=&amp; -3.056208.
\end{eqnarray*}\]</span></p>
<p>To compare the Central region with Napa Valley, we have <span class="math inline">\(H_0: \beta_3 = 0, H_a: \beta_3 \neq 0\)</span>. The test statistic is</p>
<p><span class="math display">\[\begin{eqnarray*}
t &amp;=&amp; \frac{\hat{\beta}_3}{se(\hat{\beta}_3)} \nonumber \\
  &amp;=&amp; \frac{-2.7569}{0.4495} \nonumber \\
  &amp;=&amp; -6.133259.
\end{eqnarray*}\]</span></p>
<p>To compare the North region with the Central region, we have <span class="math inline">\(H_0: \beta_2 - \beta_3 = 0, H_a: \beta_2 - \beta_3 \neq 0\)</span>. The test statistic is</p>
<p><span class="math display">\[\begin{eqnarray*}
t &amp;=&amp; \frac{\hat{\beta}_2 - \hat{\beta}_3}{se(\hat{\beta}_2 - \hat{\beta}_3)} \nonumber \\
  &amp;=&amp; \frac{-1.2234 + 2.7569}{\sqrt{0.160 + 0.202 - 2 \times 0.113}} \nonumber \\
  &amp;=&amp; 4.158286.
\end{eqnarray*}\]</span></p>
<p>The critical value is 2.518259, found using <code>qt(1-0.05/(2*3), 38-4)</code>. The magnitudes of all of these test statistics are larger than the critical value, so there is a significant difference in mean quality rating of wines between which pair of regions, when controlling for flavor rating.</p>
<p><em>View the associated video and the additional set of notes for an explanation of the rationale behind the Bonferroni procedure.</em></p>
</div>
</div>
<div id="tukey-procedure" class="section level3" number="8.5.4">
<h3>
<span class="header-section-number">8.5.4</span> Tukey procedure<a class="anchor" aria-label="anchor" href="#tukey-procedure"><i class="fas fa-link"></i></a>
</h3>
<p>The calculations involved in the Tukey procedure are a little bit more involved so we will not cover the details. We can take a look at some output based on the Tukey procedure:</p>
<div class="sourceCode" id="cb313"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://multcomp.R-forge.R-project.org">multcomp</a></span><span class="op">)</span></span>
<span><span class="va">pairwise</span><span class="op">&lt;-</span><span class="fu">multcomp</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/multcomp/man/glht.html">glht</a></span><span class="op">(</span><span class="va">reduced</span>, linfct <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/multcomp/man/glht.html">mcp</a></span><span class="op">(</span>Region<span class="op">=</span> <span class="st">"Tukey"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pairwise</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = Quality ~ Flavor + Region, data = Data)
## 
## Linear Hypotheses:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## North - Napa == 0     -1.2234     0.4003  -3.056 0.011669 *  
## Central - Napa == 0   -2.7569     0.4495  -6.134  &lt; 1e-04 ***
## Central - North == 0  -1.5335     0.3688  -4.158 0.000606 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>Each line is showing the result of testing if the mean quality rating differs between the listed pair of regions (when controlling for flavor rating). We note that the results of all three hypothesis tests are significant. So the data support the claim that there is significant difference in the mean quality of wines between all pairs of regions, when controlling for flavor rating.</p>
<p>Given the negative values for the difference in the estimated coefficients, wines from the
Napa valley have the highest ratings, followed by wines from the North region, and then
wines from the Central region, when flavor rating is controlled.</p>
</div>
<div id="comments-about-multiple-comparisons" class="section level3" number="8.5.5">
<h3>
<span class="header-section-number">8.5.5</span> Comments about Multiple Comparisons<a class="anchor" aria-label="anchor" href="#comments-about-multiple-comparisons"><i class="fas fa-link"></i></a>
</h3>
<p>These procedures to handle multiple pairwise comparisons require there to be no interactions involving the categorical predictor, as we assume the difference in the mean response is the same as long as we control the other predictors.</p>
<p>Some comments about the Bonferroni procedure:</p>
<ul>
<li>The probability of making at least one Type I error is <span class="math inline">\(\leq \alpha\)</span>. As <span class="math inline">\(g\)</span> increases, this probability becomes a lot less than <span class="math inline">\(\alpha\)</span>.</li>
<li>A by product is that <strong>power</strong> (the ability to correctly reject the null hypothesis) is sacrificed, especially as <span class="math inline">\(g\)</span> increases.</li>
<li>Confidence intervals have a higher level of confidence and are wider.</li>
<li>Bonferroni procedure is <strong>considered conservative</strong> (less powerful, wider intervals).</li>
<li>Fine to use if <span class="math inline">\(g\)</span> is known prior to looking at the data and is small.</li>
<li>Easy to implement with simple adjustment to multiplier and critical value.</li>
</ul>
<p>On the other hand, the Tukey procedure is less conservative and more powerful. Typically used when <span class="math inline">\(g\)</span> is larger.</p>
</div>
</div>
<div id="practical-considerations" class="section level2" number="8.6">
<h2>
<span class="header-section-number">8.6</span> Practical Considerations<a class="anchor" aria-label="anchor" href="#practical-considerations"><i class="fas fa-link"></i></a>
</h2>
<div id="categorical-predictor-with-many-levels" class="section level3" number="8.6.1">
<h3>
<span class="header-section-number">8.6.1</span> Categorical predictor with many levels<a class="anchor" aria-label="anchor" href="#categorical-predictor-with-many-levels"><i class="fas fa-link"></i></a>
</h3>
<p>For a categorical predictor with many levels, the output can be daunting to look at, as the number of indicator variables (and hence number of regression coefficients) increases as we have more levels. A few things to consider:</p>
<ul>
<li>Are you really interested in exploring the differences in the mean response across all the levels?</li>
<li>Is there a logical way to <strong>collapse</strong> some levels together that still answers your research question and reduces the number of regression parameters?</li>
<li>Having more parameters than needed may lead to poorer predictive performance.</li>
</ul>
</div>
<div id="discrete-predictors" class="section level3" number="8.6.2">
<h3>
<span class="header-section-number">8.6.2</span> Discrete predictors<a class="anchor" aria-label="anchor" href="#discrete-predictors"><i class="fas fa-link"></i></a>
</h3>
<p>Do we treat discrete predictors as quantitative or categorical in MLR? A few things to consider:</p>
<ul>
<li>Are we fine with assuming they have a ``linear” relationship with the response variable? If yes, more likely we should treat the variable as quantitative.</li>
<li>How many distinct values are there in the discrete variable? The more distinct values, the more likely we should treat the variable as quantitative.</li>
<li>Are we concerned about needlessly adding parameters to our model especially if we have a small sample size? If yes, more likely we should treat the variable as quantitative.</li>
</ul>
</div>
</div>
<div id="r-tutorial-5" class="section level2" number="8.7">
<h2>
<span class="header-section-number">8.7</span> R Tutorial<a class="anchor" aria-label="anchor" href="#r-tutorial-5"><i class="fas fa-link"></i></a>
</h2>
<p>In this tutorial, we will use the data set <code>wine.txt</code>. The data set contains ratings of various wines produced in California. We will focus on the response variable <span class="math inline">\(y=\)</span><code>Quality</code> (average quality rating), <span class="math inline">\(x_1=\)</span><code>Flavor</code> (average flavor rating), and <code>Region</code> indicating which of three regions in California the wine is produced in. The regions are coded <span class="math inline">\(1=\)</span> <code>North</code>, <span class="math inline">\(2=\)</span> <code>Central</code>, and <span class="math inline">\(3=\)</span> <code>Napa</code>.</p>
<p>Read the data in and also load the <code>tidyverse</code> package</p>
<div class="sourceCode" id="cb315"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="va">Data</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.table</a></span><span class="op">(</span><span class="st">"wine.txt"</span>, header<span class="op">=</span><span class="cn">TRUE</span>, sep<span class="op">=</span><span class="st">""</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">Data</span><span class="op">)</span></span></code></pre></div>
<pre><code>##   Clarity Aroma Body Flavor Oakiness Quality Region
## 1       1   3.3  2.8    3.1      4.1     9.8      1
## 2       1   4.4  4.9    3.5      3.9    12.6      1
## 3       1   3.9  5.3    4.8      4.7    11.9      1
## 4       1   3.9  2.6    3.1      3.6    11.1      1
## 5       1   5.6  5.1    5.5      5.1    13.3      1
## 6       1   4.6  4.7    5.0      4.1    12.8      1</code></pre>
<div id="data-wrangling" class="section level3 unnumbered">
<h3>Data Wrangling<a class="anchor" aria-label="anchor" href="#data-wrangling"><i class="fas fa-link"></i></a>
</h3>
<p>Notice from the description that the variable <code>Region</code> is recorded numerically, even though it is a categorical variable. We need to make sure that R is viewing its type correctly by applying the function <code><a href="https://rdrr.io/r/base/class.html">class()</a></code> to this variable:</p>
<div class="sourceCode" id="cb317"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##is Region a factor?</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "integer"</code></pre>
<p>We need to convert <code>Region</code> to be viewed as categorical by using <code><a href="https://rdrr.io/r/base/factor.html">factor()</a></code>, otherwise R will treat it as a quantitative predictor and not use dummy coding:</p>
<div class="sourceCode" id="cb319"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##convert Region to factor</span></span>
<span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span> </span>
<span><span class="co">##check Region is now the correct type</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/class.html">class</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span> </span></code></pre></div>
<pre><code>## [1] "factor"</code></pre>
<p>We can check how the levels are being described:</p>
<div class="sourceCode" id="cb321"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##how are levels described</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "1" "2" "3"</code></pre>
<p>Notice the names of the levels of the regions are not descriptive. We should also give more descriptive names to the levels of <code>Region</code>:</p>
<div class="sourceCode" id="cb323"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##Give names to the levels</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"North"</span>, <span class="st">"Central"</span>, <span class="st">"Napa"</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/base/levels.html">levels</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "North"   "Central" "Napa"</code></pre>
<p>We have done the needed data wrangling: making sure categorical variables are viewed as factors, and giving descriptive names to the levels of the categorical variable.</p>
<p>Note: if categorical variables are already dummy coded, we do not need to convert them to factor when fitting MLR using <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. The <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function converts factors to dummy codes.</p>
</div>
<div id="scatterplot-with-categorical-predictor" class="section level3 unnumbered">
<h3>Scatterplot with categorical predictor<a class="anchor" aria-label="anchor" href="#scatterplot-with-categorical-predictor"><i class="fas fa-link"></i></a>
</h3>
<p>Since we have a quantitative response variable, <code>Quality</code>, a quantitative predictor <code>Flavor</code> and a categorical predictor <code>Region</code>, we can create a scatterplot, with <code>Quality</code> on the y-axis, <code>Flavor</code> on the x-axis, and use different colored plots to denote the different regions:</p>
<div class="sourceCode" id="cb325"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">Data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">Flavor</span>, y<span class="op">=</span><span class="va">Quality</span>, color<span class="op">=</span><span class="va">Region</span><span class="op">)</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method<span class="op">=</span><span class="va">lm</span>, se<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span><span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Scatterplot of Wine Quality against Flavor, by Region"</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-224-1.png" width="672"></div>
<p>We notice a positive linear association between <code>Quality</code> and <code>Flavor</code> across all three regions, the better the flavor of the wine, the higher the quality rating of the wine.</p>
<p>The slopes are not exactly parallel, indicating that there may exist an interaction between the region of the wine and its flavor; the impact of flavor on quality rating differs among the regions. So a regression model with interaction between region and flavor may be appropriate.</p>
</div>
<div id="fitting-mlr" class="section level3 unnumbered">
<h3>Fitting MLR<a class="anchor" aria-label="anchor" href="#fitting-mlr"><i class="fas fa-link"></i></a>
</h3>
<p>Since the categorical variable <code>Region</code> has three levels, we know that there will be two indicator variables created to represent the various regions. We check the dummy coding using the <code><a href="https://rdrr.io/r/stats/contrasts.html">contrasts()</a></code> function:</p>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##check dummy coding</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span></span></code></pre></div>
<pre><code>##         Central Napa
## North         0    0
## Central       1    0
## Napa          0    1</code></pre>
<p>This output informs us the <code>North</code> region is the reference class, as it is coded 0 for both indicator variables. We can change the reference class to the <code>Napa</code> region via the <code><a href="https://rdrr.io/r/stats/relevel.html">relevel()</a></code> function:</p>
<div class="sourceCode" id="cb328"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##Set a different reference class</span></span>
<span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/relevel.html">relevel</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span>, ref <span class="op">=</span> <span class="st">"Napa"</span><span class="op">)</span> </span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/contrasts.html">contrasts</a></span><span class="op">(</span><span class="va">Data</span><span class="op">$</span><span class="va">Region</span><span class="op">)</span></span></code></pre></div>
<pre><code>##         North Central
## Napa        0       0
## North       1       0
## Central     0       1</code></pre>
<p>Based on the possibility of non-parallel slopes in the scatterplot, we consider fitting a regression model with an interaction term between the predictors:</p>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">result</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Quality</span><span class="op">~</span><span class="va">Flavor</span><span class="op">*</span><span class="va">Region</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Quality ~ Flavor * Region, data = Data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.94964 -0.58463  0.04393  0.49607  1.97295 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)           10.1144     1.6692   6.060 9.14e-07 ***
## Flavor                 0.7957     0.2936   2.710   0.0107 *  
## RegionNorth           -3.3833     2.0153  -1.679   0.1029    
## RegionCentral         -6.2775     2.4491  -2.563   0.0153 *  
## Flavor:RegionNorth     0.4029     0.3878   1.039   0.3066    
## Flavor:RegionCentral   0.7137     0.4992   1.430   0.1625    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.8914 on 32 degrees of freedom
## Multiple R-squared:  0.8357, Adjusted R-squared:  0.8101 
## F-statistic: 32.56 on 5 and 32 DF,  p-value: 1.179e-11</code></pre>
<div class="sourceCode" id="cb332"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##notice hierarchical principle is used</span></span></code></pre></div>
<p>Given that the <span class="math inline">\(t\)</span> tests for the interaction terms are insignificant, we conduct a partial <span class="math inline">\(F\)</span> test to see if all the interaction terms can be dropped:</p>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##fit regression with no interaction</span></span>
<span><span class="va">reduced</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">Quality</span><span class="op">~</span><span class="va">Flavor</span><span class="op">+</span><span class="va">Region</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="co">##general linear F test for interaction terms</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">reduced</span>,<span class="va">result</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: Quality ~ Flavor + Region
## Model 2: Quality ~ Flavor * Region
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     34 27.213                           
## 2     32 25.429  2    1.7845 1.1229 0.3378</code></pre>
<p>The insignificant result of the partial <span class="math inline">\(F\)</span> test means we can drop the interaction terms. There is little evidence that the slopes are truly different.</p>
<p>The regression assumptions when a categorical predictor is involved are pretty much the same, assessed similarly as before.</p>
<div class="sourceCode" id="cb335"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span></span></code></pre></div>
<div class="inline-figure"><img src="bookdown-demo_files/figure-html/unnamed-chunk-229-1.png" width="672"></div>
</div>
<div id="multiple-comparisons" class="section level3 unnumbered">
<h3>Multiple comparisons<a class="anchor" aria-label="anchor" href="#multiple-comparisons"><i class="fas fa-link"></i></a>
</h3>
<p>Since we have a model with no interactions, we can interpret the coefficients of the indicator variables as the difference in the mean quality rating, given the flavor rating, between the class in question and the reference class. Our regression equation is</p>
<p><span class="math display">\[
E(y|x) = \beta_0 + \beta_1 x_1 + \beta_2 I_1 + \beta_3 I_2
\]</span>
where <span class="math inline">\(I_1 = 1\)</span> if <code>North</code> and 0 otherwise, <span class="math inline">\(I_2 = 1\)</span> if <code>Central</code> and 0 otherwise.</p>
<p>Plugging in the values of the indicator variables, we can write regression equations for each region</p>
<ul>
<li>
<code>North</code>: <span class="math inline">\(E(y|x) = \beta_0 + \beta_ 2 + \beta_1 x_1\)</span>.</li>
<li>
<code>Central</code>: <span class="math inline">\(E(y|x) = \beta_0 + \beta_ 3 + \beta_1 x_1\)</span>.</li>
<li>
<code>Napa</code>: <span class="math inline">\(E(y|x) = \beta_0 + \beta_1 x_1\)</span>.</li>
</ul>
<p>Since there are 3 levels, there will be 3 possible pairs of regions to compare (while controlling for flavor rating):</p>
<ul>
<li>
<code>North</code> and <code>Napa</code>: denoted by <span class="math inline">\(\beta_ 2\)</span>
</li>
<li>
<code>Central</code> and <code>Napa</code>: denoted by <span class="math inline">\(\beta_ 3\)</span>
</li>
<li>
<code>North</code> and <code>Central</code>: <span class="math inline">\(\beta_2 - \beta_3\)</span>
</li>
</ul>
<p>Let’s take a look at the estimated coefficients</p>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Quality ~ Flavor + Region, data = Data)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.97630 -0.58844  0.02184  0.51572  1.94232 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     8.3177     1.0100   8.235 1.31e-09 ***
## Flavor          1.1155     0.1738   6.417 2.49e-07 ***
## RegionNorth    -1.2234     0.4003  -3.056  0.00435 ** 
## RegionCentral  -2.7569     0.4495  -6.134 5.78e-07 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.8946 on 34 degrees of freedom
## Multiple R-squared:  0.8242, Adjusted R-squared:  0.8087 
## F-statistic: 53.13 on 3 and 34 DF,  p-value: 6.358e-13</code></pre>
<p>The estimated difference in the mean quality rating between the sampled wines in the <code>North</code> and <code>Napa</code> regions is -1.22, for given flavor ratings.</p>
<p>The first two comparisons are easy as we can just refer to the coefficients for the indicator variables. A little bit of work needs to be done to compare the <code>North</code> and <code>Central</code> regions. Also, note we are performing three hypothesis tests. So we need to use multiple comparison methods to ensure that the probability of making at least one Type I error is at most the significance level of 0.05.</p>
<div id="bonferroni-procedure-1" class="section level4 unnumbered">
<h4>Bonferroni procedure<a class="anchor" aria-label="anchor" href="#bonferroni-procedure-1"><i class="fas fa-link"></i></a>
</h4>
<p>As noted earlier, there are 3 pairs of regions to compare (while controlling for flavor rating):</p>
<ul>
<li>
<code>North</code> and <code>Napa</code>: denoted by <span class="math inline">\(\beta_ 2\)</span>
</li>
<li>
<code>Central</code> and <code>Napa</code>: denoted by <span class="math inline">\(\beta_ 3\)</span>
</li>
<li>
<code>North</code> and `Central: <span class="math inline">\(\beta_2 - \beta_3\)</span>
</li>
</ul>
<p>The t multiplier and critical value is now <span class="math inline">\(t_{1-\frac{\alpha}{2g}, n-p}\)</span>, which we can find with:</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">n</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Data</span><span class="op">)</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="va">p</span><span class="op">&lt;-</span><span class="fl">4</span></span>
<span><span class="va">g</span><span class="op">&lt;-</span><span class="fl">3</span></span>
<span><span class="va">t.bon</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">qt</a></span><span class="op">(</span><span class="fl">1</span><span class="op">-</span><span class="fl">0.05</span><span class="op">/</span><span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">g</span><span class="op">)</span>, <span class="va">n</span><span class="op">-</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="va">t.bon</span></span></code></pre></div>
<pre><code>## [1] 2.518259</code></pre>
<div id="pairwise-comparison-with-reference-class" class="section level5 unnumbered">
<h5>Pairwise comparison with reference class<a class="anchor" aria-label="anchor" href="#pairwise-comparison-with-reference-class"><i class="fas fa-link"></i></a>
</h5>
<p>For the difference in mean quality rating between wines in the North and Napa regions, when controlling for flavor, we use the confidence interval for <span class="math inline">\(\beta_2\)</span>, i.e.,</p>
<p><span class="math display">\[
\hat{\beta}_2 \pm t_{1-\frac{\alpha}{2g}, n-p} se(\hat{\beta}_2) = {-1.2234} \pm 2.518259 \times 0.4003 = (-2.2315, -0.2153)
\]</span></p>
<p>which excludes 0, so we have a significant difference in the mean quality rating between wines in the North and Napa regions, when controlling for flavor. Since the interval is negative, we can say that the mean quality rating for wines in the Napa region is higher than the North region, when controlling for flavor.</p>
<p>To conduct the hypothesis test <span class="math inline">\(H_0: \beta_2 = 0, H_a: \beta_2 \neq 0\)</span>, we can use the critical value (which is the same as the t multiplier) of 2.518259. The test statistic is</p>
<p><span class="math display">\[
\frac{\hat{\beta}_2}{se(\hat{\beta}_2)} = \frac{-1.2234}{0.4003} = -3.056
\]</span>
which is larger in magnitude than the critical value, so we reject the null hypothesis.</p>
<p>Notice the result from the confidence interval and hypothesis test are consistent at the same level of significance.</p>
</div>
<div id="pairwise-comparison-excluding-reference-class" class="section level5 unnumbered">
<h5>Pairwise comparison excluding reference class<a class="anchor" aria-label="anchor" href="#pairwise-comparison-excluding-reference-class"><i class="fas fa-link"></i></a>
</h5>
<p>Comparisons excluding the reference require a bit more work. For the difference in mean quality rating between wines in the North and Central regions, when controlling for flavor, we use the CI for <span class="math inline">\(\beta_2 - \beta_3\)</span>:</p>
<p><span class="math display">\[
(\hat{\beta}_2 - \hat{\beta}_3) \pm t_{1-\frac{\alpha}{2g}, n-p} se(\hat{\beta}_2 - \hat{\beta}_3)
\]</span></p>
<p>The output from <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> does not provide <span class="math inline">\(se(\hat{\beta}_2 - \hat{\beta}_3)\)</span>. To obtain the values to calculate this, we need to produce the variance-covariance matrix for the estimated coefficients</p>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/vcov.html">vcov</a></span><span class="op">(</span><span class="va">reduced</span><span class="op">)</span></span></code></pre></div>
<pre><code>##               (Intercept)      Flavor RegionNorth RegionCentral
## (Intercept)     1.0201363 -0.16975148 -0.27722389   -0.27700199
## Flavor         -0.1697515  0.03022282  0.03748222    0.03744271
## RegionNorth    -0.2772239  0.03748222  0.16026554    0.11313506
## RegionCentral  -0.2770020  0.03744271  0.11313506    0.20201780</code></pre>
<p>So we have</p>
<p><span class="math display">\[
Var(\hat{\beta}_2-\hat{\beta}_3) = Var(\hat{\beta}_2) + Var(\hat{\beta}_3) - 2Cov(\hat{\beta}_2,\hat{\beta}_3) = 0.1603 + 0.2020 - 2 \times 0.1131 = 0.1361
\]</span>
Therefore, the CI for <span class="math inline">\(\beta_2 - \beta_3\)</span> is</p>
<p><span class="math display">\[
(-1.2234 - -2.7569 ) \pm 2.518259 \times \sqrt{0.1361} = (0.6045, 2.4625)
\]</span>
which excludes 0, so we have a significant difference in the mean quality rating between wines in the North and Central regions, when controlling for flavor. Since the interval is positive, we can say that the mean quality rating for wines in the North region is higher than the Central region, when controlling for flavor.</p>
<p>To perform the hypothesis test <span class="math inline">\(H_0: \beta_2 - \beta_3 = 0, H_a: \beta_2 - \beta_3 \neq 0\)</span>, we need to calculate the t-statistic</p>
<p><span class="math display">\[
t-stat = \frac{\hat{\beta}_2 - \hat{\beta}_3}{se(\hat{\beta}_2 - \hat{\beta}_3)} = \frac{-1.2234 - -2.7569}{\sqrt{0.1361}} = 4.1568
\]</span>
which is larger in magnitude than the critical value of 2.518259, so we reject the null hypothesis. Again, the conclusions from the hypothesis test and CI are consistent.</p>
</div>
</div>
<div id="tukey-procedure-1" class="section level4 unnumbered">
<h4>Tukey procedure<a class="anchor" aria-label="anchor" href="#tukey-procedure-1"><i class="fas fa-link"></i></a>
</h4>
<p>Another procedure for multiple pairwise comparisons is the Tukey procedure. We use the <code><a href="https://rdrr.io/pkg/multcomp/man/glht.html">glht()</a></code> function from the <code>multcomp</code> package</p>
<div class="sourceCode" id="cb342"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://multcomp.R-forge.R-project.org">multcomp</a></span><span class="op">)</span></span>
<span><span class="va">pairwise</span><span class="op">&lt;-</span><span class="fu">multcomp</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/multcomp/man/glht.html">glht</a></span><span class="op">(</span><span class="va">reduced</span>, linfct <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/multcomp/man/glht.html">mcp</a></span><span class="op">(</span>Region<span class="op">=</span> <span class="st">"Tukey"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">pairwise</span><span class="op">)</span></span></code></pre></div>
<pre><code>## 
##   Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: lm(formula = Quality ~ Flavor + Region, data = Data)
## 
## Linear Hypotheses:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## North - Napa == 0     -1.2234     0.4003  -3.056 0.011651 *  
## Central - Napa == 0   -2.7569     0.4495  -6.134  &lt; 1e-04 ***
## Central - North == 0  -1.5335     0.3688  -4.158 0.000573 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## (Adjusted p values reported -- single-step method)</code></pre>
<p>We can see that there is a significant difference in the mean Quality rating for all pairs of regions, for given flavor rating, since these tests are all significant.</p>
<p>Given the negative values for the difference in the estimated coefficients, wines from the Napa valley have the highest ratings, followed by wines from the North region, and then wines from the Central region, when flavor rating is controlled.</p>

</div>
</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="genF.html"><span class="header-section-number">7</span> General Linear \(F\) Test and Multicollinearity</a></div>
<div class="next"><a href="crit.html"><span class="header-section-number">9</span> Model Selection Criteria and Automated Search Procedures</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#cat"><span class="header-section-number">8</span> Categorical Predictors in MLR</a></li>
<li>
<a class="nav-link" href="#introduction-7"><span class="header-section-number">8.1</span> Introduction</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#quantitative-vs-categorical-variable"><span class="header-section-number">8.1.1</span> Quantitative vs categorical variable</a></li></ul>
</li>
<li>
<a class="nav-link" href="#indicator-variables-and-dummy-coding"><span class="header-section-number">8.2</span> Indicator Variables and Dummy Coding</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#indicator-variables"><span class="header-section-number">8.2.1</span> Indicator variables</a></li>
<li><a class="nav-link" href="#dummy-coding"><span class="header-section-number">8.2.2</span> Dummy coding</a></li>
<li><a class="nav-link" href="#regression-coefficient-interpretation"><span class="header-section-number">8.2.3</span> Regression coefficient interpretation</a></li>
<li><a class="nav-link" href="#thought-question"><span class="header-section-number">8.2.4</span> Thought question</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#interaction-terms"><span class="header-section-number">8.3</span> Interaction Terms</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#consideration-of-interaction-terms"><span class="header-section-number">8.3.1</span> Consideration of interaction terms</a></li>
<li><a class="nav-link" href="#interaction-vs-correlation"><span class="header-section-number">8.3.2</span> Interaction vs correlation</a></li>
<li><a class="nav-link" href="#dummy-coding-vs-separate-regressions"><span class="header-section-number">8.3.3</span> Dummy coding vs separate regressions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#beyond-binary-predictors"><span class="header-section-number">8.4</span> Beyond Binary Predictors</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#difference-in-mean-response-between-levels-excluding-the-reference-class"><span class="header-section-number">8.4.1</span> Difference in mean response between levels excluding the reference class</a></li>
<li><a class="nav-link" href="#interactions"><span class="header-section-number">8.4.2</span> Interactions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#pairwise-comparisons"><span class="header-section-number">8.5</span> Pairwise Comparisons</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#significance-level"><span class="header-section-number">8.5.1</span> Significance level</a></li>
<li><a class="nav-link" href="#multiple-pairwise-comparisons"><span class="header-section-number">8.5.2</span> Multiple pairwise comparisons</a></li>
<li><a class="nav-link" href="#bonferroni-procedure"><span class="header-section-number">8.5.3</span> Bonferroni procedure</a></li>
<li><a class="nav-link" href="#tukey-procedure"><span class="header-section-number">8.5.4</span> Tukey procedure</a></li>
<li><a class="nav-link" href="#comments-about-multiple-comparisons"><span class="header-section-number">8.5.5</span> Comments about Multiple Comparisons</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#practical-considerations"><span class="header-section-number">8.6</span> Practical Considerations</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#categorical-predictor-with-many-levels"><span class="header-section-number">8.6.1</span> Categorical predictor with many levels</a></li>
<li><a class="nav-link" href="#discrete-predictors"><span class="header-section-number">8.6.2</span> Discrete predictors</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#r-tutorial-5"><span class="header-section-number">8.7</span> R Tutorial</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#data-wrangling">Data Wrangling</a></li>
<li><a class="nav-link" href="#scatterplot-with-categorical-predictor">Scatterplot with categorical predictor</a></li>
<li><a class="nav-link" href="#fitting-mlr">Fitting MLR</a></li>
<li><a class="nav-link" href="#multiple-comparisons">Multiple comparisons</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Linear Models for Data Science</strong>" was written by Jeffrey Woo. It was last built on 2024-07-15.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
