<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 9 Model Selection Criteria and Automated Search Procedures | Linear Models for Data Science</title>
<meta name="author" content="Jeffrey Woo">
<meta name="description" content="9.1 Introduction In building a regression model, we are faced with two conflicting objectives: to include more predictors into the model so as to improve the predictive ability of the model and to...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Chapter 9 Model Selection Criteria and Automated Search Procedures | Linear Models for Data Science">
<meta property="og:type" content="book">
<meta property="og:description" content="9.1 Introduction In building a regression model, we are faced with two conflicting objectives: to include more predictors into the model so as to improve the predictive ability of the model and to...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 9 Model Selection Criteria and Automated Search Procedures | Linear Models for Data Science">
<meta name="twitter:description" content="9.1 Introduction In building a regression model, we are faced with two conflicting objectives: to include more predictors into the model so as to improve the predictive ability of the model and to...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Linear Models for Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">1</span> Data Wrangling with R</a></li>
<li><a class="" href="viz.html"><span class="header-section-number">2</span> Data Visualization with R Using ggplot2</a></li>
<li><a class="" href="slr.html"><span class="header-section-number">3</span> Basics with Simple Linear Regression (SLR)</a></li>
<li><a class="" href="inf.html"><span class="header-section-number">4</span> Inference with Simple Linear Regression (SLR)</a></li>
<li><a class="" href="diag.html"><span class="header-section-number">5</span> Model Diagnostics and Remedial Measures in SLR</a></li>
<li><a class="" href="mlr.html"><span class="header-section-number">6</span> Multiple Linear Regression (MLR)</a></li>
<li><a class="" href="genF.html"><span class="header-section-number">7</span> General Linear \(F\) Test and Multicollinearity</a></li>
<li><a class="" href="cat.html"><span class="header-section-number">8</span> Categorical Predictors in MLR</a></li>
<li><a class="active" href="crit.html"><span class="header-section-number">9</span> Model Selection Criteria and Automated Search Procedures</a></li>
<li><a class="" href="out.html"><span class="header-section-number">10</span> Analysis of Residuals in MLR</a></li>
<li><a class="" href="logistic1.html"><span class="header-section-number">11</span> Logistic Regression</a></li>
<li><a class="" href="logistic2.html"><span class="header-section-number">12</span> Logistic Regression 2</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="crit" class="section level1" number="9">
<h1>
<span class="header-section-number">9</span> Model Selection Criteria and Automated Search Procedures<a class="anchor" aria-label="anchor" href="#crit"><i class="fas fa-link"></i></a>
</h1>
<div id="introduction-8" class="section level2" number="9.1">
<h2>
<span class="header-section-number">9.1</span> Introduction<a class="anchor" aria-label="anchor" href="#introduction-8"><i class="fas fa-link"></i></a>
</h2>
<p>In building a regression model, we are faced with two conflicting objectives:</p>
<ol style="list-style-type: decimal">
<li>to include more predictors into the model so as to improve the predictive ability of the model and</li>
<li>to not include predictors that are unnecessary, which will lead to more uncertainty in our predictions and make our model needlessly complicated, making predictions and interpretations more challenging.</li>
</ol>
<p>For example, recall the NFL dataset that you have seen and worked on in the previous modules. In the data set, you are presented with 9 potential predictors to predict the number of wins for a team. You are faced with the question of which and how many of the predictors you will need to include in the model. Do we start by using just offensive statistics, or should we start by also including the strength of schedule? Or why not just use all of the predictors right away?</p>
<p>In this module, you will learn the various ways to assess different competing models.</p>
</div>
<div id="model-assessment-concepts" class="section level2" number="9.2">
<h2>
<span class="header-section-number">9.2</span> Model Assessment Concepts<a class="anchor" aria-label="anchor" href="#model-assessment-concepts"><i class="fas fa-link"></i></a>
</h2>
<p>Previously, we looked at <strong>model diagnostics</strong>, which are tools to assess if the assumptions for a regression model are met. We are assessing if the assumption that the error terms in a regression model and independent and identically distributed as a normal distribution with mean 0 and constant variance denoted by <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Meeting the assumptions do not guarantee that the model fits the data well, as the variance of the error terms could be large. We now shift our attention to <strong>model assessment</strong>, which measures how well the model fits the data and how well the model predicts future observations.</p>
<p>Recall there are two main uses of regression models:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Prediction</strong>: Predict a future value of a response variable, using information from predictor variables.</li>
<li>
<strong>Association</strong>: Quantify the relationship between variables. How does a change in a predictor variable change the value of the response variable, on average?</li>
</ol>
<p>With multiple predictors to choose from, we need a way to chose between all the possible models that we can fit. For example, if we have <span class="math inline">\(k\)</span> predictors, then there are <span class="math inline">\(2^{k}\)</span> possible models with just additive effects to consider. What predictors should we include?</p>
<ul>
<li><p>Generally speaking, we can improve the model fit (in terms of improving <span class="math inline">\(R^2\)</span> or reducing <span class="math inline">\(SS_{res}\)</span>) by adding more predictors (even if added needlessly).</p></li>
<li><p>However, if we needlessly add in predictors, the predictive ability of a model can suffer, and we make the model more difficult to interpret.</p></li>
</ul>
<p>So we can see that needlessly adding predictors negatively affects both uses of regression models. Generally, we apply the principle of “Ockham’s razor”:
Given two theories that describe a phenomenon equally well, we should prefer the theory that is simpler. In selecting regression models, we should choose the one with fewer parameters when there are multiple models that give nearly the same fit to the data. We always should be asking: does the improvement in fit for models with more parameters justify the extra complexity?</p>
<p>Model assessment can be viewed as a trade-off between model complexity and model fit, so the model can be interpreted and predicts well on future data.</p>
<div id="training-and-test-data" class="section level3" number="9.2.1">
<h3>
<span class="header-section-number">9.2.1</span> Training and test data<a class="anchor" aria-label="anchor" href="#training-and-test-data"><i class="fas fa-link"></i></a>
</h3>
<p>By now, you should realize that a model that fits the data well does not necessarily predict well on future observations. We introduce the definitions of training and test data:</p>
<ul>
<li>
<strong>Training data</strong>: are the observations used to build the regression model.</li>
<li>
<strong>Test data</strong>: are the observations that were not used to build the regression model and are solely used to assess how well the model predicts future observations.</li>
</ul>
<p>Model fit typically measures how well the training data fits the model (e.g. <span class="math inline">\(R^2\)</span>, <span class="math inline">\(SS_{res}\)</span>). Model assessment measures how well the model does in predicting the test data.</p>
</div>
<div id="overfitting" class="section level3" number="9.2.2">
<h3>
<span class="header-section-number">9.2.2</span> Overfitting<a class="anchor" aria-label="anchor" href="#overfitting"><i class="fas fa-link"></i></a>
</h3>
<p>A model that fits the training data well is not guaranteed to predict test data. In fact, a model that performs a lot worse on test data than on training data is an indication that the model is needlessly complicated. Such a model is <strong>overfitted</strong>.</p>
<p>It may seem counter intuitive that a model that has more parameters could perform worse on test data. The reason is the following: we have mentioned that models take the form <span class="math inline">\(y = f(\boldsymbol{x}) + \epsilon\)</span>, where the function <span class="math inline">\(f\)</span> denotes the true relationship between the response and predictor variables, and <span class="math inline">\(\epsilon\)</span> denotes the random error. A model that is overfitted fails to account for the errors properly by incorporating the errors into the estimation of <span class="math inline">\(f\)</span>, so the estimated <span class="math inline">\(f\)</span> is not a good approximation for the true relationship <span class="math inline">\(f\)</span>. So we end up using this poor approximation for <span class="math inline">\(f\)</span> in predicting test data.</p>
<p>Model selection criteria are used to select between several models by assessing the models in terms of model fit and model complexity. These criteria prevent overfitting from happening.</p>
</div>
</div>
<div id="model-selection-criteria" class="section level2" number="9.3">
<h2>
<span class="header-section-number">9.3</span> Model Selection Criteria<a class="anchor" aria-label="anchor" href="#model-selection-criteria"><i class="fas fa-link"></i></a>
</h2>
<p>A variety of model selection criteria have been proposed to assess regression models. These criteria typically measure the model fit and have a penalty for each additional parameter. The penalty penalizes the model when it gets too complicated.</p>
<p>The coefficient of determination, <span class="math inline">\(R^2\)</span>, is typically not used as a model selection criteria, since it always increases when we add parameters to the model, and so will favor more models that add parameters. <span class="math inline">\(R^2\)</span> does not have a penalty for each additional parameter. <span class="math inline">\(R^2\)</span> can be used when comparing models with the same number of parameters.</p>
<p>We will next look at various model selection criteria that have a penalty for each additional parameter.</p>
<div id="adjusted-r-squared-r_adjp2" class="section level3" number="9.3.1">
<h3>
<span class="header-section-number">9.3.1</span> Adjusted R-squared: <span class="math inline">\(R_{Adj,p}^{2}\)</span><a class="anchor" aria-label="anchor" href="#adjusted-r-squared-r_adjp2"><i class="fas fa-link"></i></a>
</h3>
<p>The adjusted R-squared, denoted by <span class="math inline">\(R_{Adj,p}^{2}\)</span>, is</p>
<p><span class="math display" id="eq:9aR2">\[\begin{equation}
R_{Adj,p}^{2} = 1 - \left( \frac{n-1}{n-p} \right) (1 - R^2_{p})
\tag{9.1}
\end{equation}\]</span></p>
<ul>
<li>
<span class="math inline">\(R_{Adj,p}^{2}\)</span> is a measure of fit with penalty for additional parameters.</li>
<li>By including one additional parameter, <span class="math inline">\(R^2_{p}\)</span> will increase and the divisor <span class="math inline">\(n-p\)</span> decreases.</li>
<li>Choosing the model with the largest <span class="math inline">\(R_{Adj,p}^{2}\)</span> is equivalent to selecting the one with the smallest <span class="math inline">\(MS_{res}(p)\)</span>.</li>
<li>Larger value is better.</li>
</ul>
</div>
<div id="mallows-c_p" class="section level3" number="9.3.2">
<h3>
<span class="header-section-number">9.3.2</span> Mallow’s <span class="math inline">\(C_p\)</span><a class="anchor" aria-label="anchor" href="#mallows-c_p"><i class="fas fa-link"></i></a>
</h3>
<p>Mallow’s <span class="math inline">\(C_p\)</span> measures the variance and bias associated with predicting test data. In the context of MLR, it is found using</p>
<p><span class="math display" id="eq:9cp">\[\begin{equation}
C_p = \frac{SS_{res}(p)}{MS_{res}(P)} - (n-2p).
\tag{9.2}
\end{equation}\]</span></p>
<ul>
<li>
<span class="math inline">\(C_p\)</span> is a measure of fit with penalty for additional parameters.</li>
<li>By including one additional parameter, <span class="math inline">\(2p\)</span> increases while <span class="math inline">\(SS_{res}\)</span> decreases.</li>
<li>
<span class="math inline">\(MS_{res}(P)\)</span> denotes the <span class="math inline">\(MS_{res}\)</span> of the model with all <span class="math inline">\(P\)</span> parameters.</li>
<li>Some authors suggest choosing the simplest model with <span class="math inline">\(C_p\)</span> closest to <span class="math inline">\(p\)</span>. The argument is that if the model is unbiased, <span class="math inline">\(C_p = p\)</span>.</li>
<li>However, unbiased models are not guaranteed to perform best on test data. So, we should select the model with the smallest <span class="math inline">\(C_p\)</span>.</li>
</ul>
</div>
<div id="aic_p-and-bic_p" class="section level3" number="9.3.3">
<h3>
<span class="header-section-number">9.3.3</span> <span class="math inline">\(AIC_p\)</span> and <span class="math inline">\(BIC_p\)</span><a class="anchor" aria-label="anchor" href="#aic_p-and-bic_p"><i class="fas fa-link"></i></a>
</h3>
<p>A couple of related measures are also used, the Akaike information criterion, <span class="math inline">\(AIC_p\)</span>, and the Bayesian information criterion, <span class="math inline">\(BIC_p\)</span>. In MLR, they are</p>
<p><span class="math display" id="eq:9aic">\[\begin{equation}
\mbox{AIC}_p = n\log \frac{SS_{res}(p)}{n} + 2p
\tag{9.3}
\end{equation}\]</span></p>
<p>and</p>
<p><span class="math display" id="eq:9bic">\[\begin{equation}
\mbox{BIC}_p = n\log \frac{SS_{res}(p)}{n} +p\log n.
\tag{9.4}
\end{equation}\]</span></p>
<ul>
<li>Both are measures of fit with penalty for additional parameters.</li>
<li>By including one additional parameter, <span class="math inline">\(2p\)</span> and <span class="math inline">\(p\log n\)</span> increase while <span class="math inline">\(SS_{res}\)</span> decreases.</li>
<li>Models with low <span class="math inline">\(AIC_p\)</span>, <span class="math inline">\(BIC_p\)</span> are desired.</li>
<li>If <span class="math inline">\(\log n &gt; 2\)</span> (i.e. <span class="math inline">\(n \geq 8\)</span>), then <span class="math inline">\(BIC_p\)</span> increases with <span class="math inline">\(p\)</span> more quickly than <span class="math inline">\(AIC_p\)</span>. Thus, <span class="math inline">\(BIC_p\)</span> favors smaller models compared to AIC.</li>
</ul>
</div>
<div id="press-statistic" class="section level3" number="9.3.4">
<h3>
<span class="header-section-number">9.3.4</span> PRESS statistic<a class="anchor" aria-label="anchor" href="#press-statistic"><i class="fas fa-link"></i></a>
</h3>
<p>The PRESS statistic measures the difference in predicted response when an observation is excluded in estimating the model. It is defined as</p>
<p><span class="math display" id="eq:9PRESS">\[\begin{equation}
PRESS = \sum_{i=1}^n\left(y_i-\hat{y}_{i(i)}\right)^2
\tag{9.5}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat{y}_{i(i)}\)</span> is the predicted value for the <span class="math inline">\(i\)</span>th observation
when the regression is fitted without the <span class="math inline">\(i\)</span>th observation.</p>
<ul>
<li>Small PRESS statistic is desired.</li>
<li>Models with small PRESS statistics have small prediction errors on test data.</li>
<li>Of the criteria listed, the PRESS statistic <a href="crit.html#eq:9PRESS">(9.5)</a> is motivated by measuring the prediction error in test data, whereas the other criteria <a href="crit.html#eq:9aR2">(9.1)</a>, <a href="crit.html#eq:9cp">(9.2)</a>, <a href="crit.html#eq:9aic">(9.3)</a>, <a href="crit.html#eq:9bic">(9.4)</a> are motivated by balancing model fit and model complexity, and as a consequence will perform well in predicting test data.</li>
</ul>
<p>A related measure to the PRESS statistic <a href="crit.html#eq:9PRESS">(9.5)</a> is <span class="math inline">\(R^2_{prediction}\)</span>,</p>
<p><span class="math display" id="eq:9R2pred">\[\begin{equation}
R^2_{prediction} = 1 - \frac{PRESS}{SS_T},
\tag{9.6}
\end{equation}\]</span></p>
<p>which can be interpreted as the <strong>proportion of the variability in the response of new observations that can be explained by our model</strong>.</p>
<ul>
<li>On average, <span class="math inline">\(R^2_{prediction}\)</span> is less than <span class="math inline">\(R^2_p\)</span>.</li>
<li>An <span class="math inline">\(R^2_{prediction}\)</span> that is a lot smaller than <span class="math inline">\(R^2_p\)</span> indicates overfitting.</li>
</ul>
</div>
<div id="summary-and-final-comments" class="section level3" number="9.3.5">
<h3>
<span class="header-section-number">9.3.5</span> Summary and final comments<a class="anchor" aria-label="anchor" href="#summary-and-final-comments"><i class="fas fa-link"></i></a>
</h3>
<p>We have introduced a number of criteria. While these criteria attempt to measure model fit and complexity, they are not mathematically equivalent. None of these should be regarded as definitive in itself, but taken together
they provide a range of possible options which, combined with some
judgment about the data themselves, can usually be used to decide
upon a model which is reasonable from all criteria. A couple of other points to note:</p>
<ul>
<li>We still need to check the model for regression assumptions.</li>
<li>These criteria can only be used to compare models with the same response variable, as they are affected by the unit associated with the response variable.</li>
</ul>
</div>
</div>
<div id="automated-search-procedures" class="section level2" number="9.4">
<h2>
<span class="header-section-number">9.4</span> Automated Search Procedures<a class="anchor" aria-label="anchor" href="#automated-search-procedures"><i class="fas fa-link"></i></a>
</h2>
<p>With multiple predictors to choose from, we need a way to choose between all the possible models that we can fit. For example, if we have <span class="math inline">\(k\)</span> quantitative predictors, then there are <span class="math inline">\(2^{k}\)</span> possible models with just additive effects to consider. If <span class="math inline">\(k\)</span> is large, then there are many models to compare. Can we automate the process of model selection to make things more computationally efficient?</p>
<div id="forward-selection-backward-elimination" class="section level3" number="9.4.1">
<h3>
<span class="header-section-number">9.4.1</span> Forward selection, backward elimination<a class="anchor" aria-label="anchor" href="#forward-selection-backward-elimination"><i class="fas fa-link"></i></a>
</h3>
<p>A couple of methods to automate this process:</p>
<ol style="list-style-type: decimal">
<li>
<strong>Forward Selection</strong>:
<ul>
<li>We begin with a model with no predictors, and add in predictor variables one at a time in some optimal way, until a desirable stopping point is reached.</li>
</ul>
</li>
<li>
<strong>Backward Elimination</strong>:
<ul>
<li>We begin with a model with all potential predictors, and then remove the “weak” predictor variables one at a time in some optimal way, until a desirable stopping point is reached.</li>
</ul>
</li>
</ol>
<p>A critical concept is that each step is conditional on the previous step. For instance, in forward selection we are adding a variable to those already selected.</p>
<p>The criterion to add (or eliminate) a predictor in each step for forward selection (or backward elimination) might be based on <span class="math inline">\(p\)</span>-value, <span class="math inline">\(SS_{res}\)</span>, <span class="math inline">\(AIC_{p}\)</span>, etc.</p>
<p>Suppose we use <span class="math inline">\(AIC_p\)</span> as the criterion. We know that smaller values of <span class="math inline">\(\mbox{AIC}_{p}\)</span> are desired.</p>
<ul>
<li>In a forward step, given a model of size <span class="math inline">\(p\)</span> in the previous step, compare all the candidate models of size <span class="math inline">\(p+1\)</span> by adding one of the remaining predictor variables. Among these size-(<span class="math inline">\(p+1\)</span>) models, select the one that results in the smallest <span class="math inline">\(AIC_{p+1}\)</span>, which is also smaller than the <span class="math inline">\(AIC_p\)</span> of the model in the previous step.</li>
<li>In a backward step, given a model of size <span class="math inline">\(p\)</span> in the previous step, compare all the candidate models of size <span class="math inline">\(p-1\)</span> by eliminating one of the existing predictors. Among these size-(<span class="math inline">\(p-1\)</span>) models, remove the one that results in the smallest <span class="math inline">\(AIC_{p-1}\)</span> value, that is also smaller than the <span class="math inline">\(AIC_p\)</span> of the model in the previous step.</li>
<li>The algorithm stops when the <span class="math inline">\(AIC\)</span> no longer decreases.</li>
</ul>
<p>Let us consider this toy example. Suppose there are four potential predictors, <span class="math inline">\(x_1,x_2,x_3,x_4\)</span>. The table below gives the <span class="math inline">\(AIC\)</span> of all possible models. Assume the AIC of the intercept-only model is 25.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="14%">
<col width="10%">
<col width="14%">
<col width="10%">
<col width="14%">
<col width="10%">
<col width="14%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th align="center">Model</th>
<th align="center">AIC</th>
<th align="center">Model</th>
<th align="center">AIC</th>
<th align="center">Model</th>
<th align="center">AIC</th>
<th align="center">Model</th>
<th align="center">AIC</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(x_1\)</span></td>
<td align="center">20</td>
<td align="center"><span class="math inline">\(x_1, x_2\)</span></td>
<td align="center">8</td>
<td align="center"><span class="math inline">\(x_1, x_2, x_3\)</span></td>
<td align="center">5</td>
<td align="center"><span class="math inline">\(x_1, x_2, x_3, x_4\)</span></td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(x_2\)</span></td>
<td align="center">17</td>
<td align="center"><span class="math inline">\(x_1, x_3\)</span></td>
<td align="center">10</td>
<td align="center"><span class="math inline">\(x_1, x_2, x_4\)</span></td>
<td align="center">7</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(x_3\)</span></td>
<td align="center">15</td>
<td align="center"><span class="math inline">\(x_1, x_4\)</span></td>
<td align="center">17</td>
<td align="center"><span class="math inline">\(x_1, x_3, x_4\)</span></td>
<td align="center">8</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(x_4\)</span></td>
<td align="center">19</td>
<td align="center"><span class="math inline">\(x_2, x_3\)</span></td>
<td align="center">11</td>
<td align="center"><span class="math inline">\(x_2, x_3, x_4\)</span></td>
<td align="center">6</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(x_2, x_4\)</span></td>
<td align="center">12</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center"></td>
<td align="center"><span class="math inline">\(x_3, x_4\)</span></td>
<td align="center">9</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table></div>
<p>Suppose we start from the intercept-only model. What model gets selected by forward election?</p>
<ul>
<li>In step 1, we will add <span class="math inline">\(x_3\)</span> to the intercept-only model. This is the model with just 1 predictor that has the smallest <span class="math inline">\(AIC\)</span> that also decreases the AIC from the previous step.</li>
<li>In step 2, we consider adding one of the three remaining predictors, <span class="math inline">\(x_1, x_2, x_4\)</span> to the model with <span class="math inline">\(x_3\)</span> already in. <span class="math inline">\(x_3\)</span> will not be removed. <span class="math inline">\(x_4\)</span> will be added because it results in the smallest <span class="math inline">\(AIC\)</span> that also decreases the AIC from the previous step.</li>
<li>In step 3, we consider adding one of the two remaining predictors, <span class="math inline">\(x_1, x_2\)</span> to the model with <span class="math inline">\(x_3, x_4\)</span> already in. <span class="math inline">\(x_2\)</span> will be added because it results in the smallest <span class="math inline">\(AIC\)</span> that also decreases the AIC from the previous step.</li>
<li>Algorithm stops here, as adding an additional predictor at this step will not decrease the AIC. So the model selected has <span class="math inline">\(x_2, x_3, x_4\)</span>.</li>
</ul>
<div id="practice-question-1" class="section level4" number="9.4.1.1">
<h4>
<span class="header-section-number">9.4.1.1</span> Practice question<a class="anchor" aria-label="anchor" href="#practice-question-1"><i class="fas fa-link"></i></a>
</h4>
<p>What model gets selected by backward elimination, if we start from the model with all 4 predictors?</p>
<p><em>View the associated video for a review of this practice question.</em></p>
</div>
<div id="stepwise-regression" class="section level4" number="9.4.1.2">
<h4>
<span class="header-section-number">9.4.1.2</span> Stepwise regression<a class="anchor" aria-label="anchor" href="#stepwise-regression"><i class="fas fa-link"></i></a>
</h4>
<p>A combination procedure called <strong>stepwise regression</strong> can also be used. It is a combination procedure because at each step, the algorithm considers adding any of the remaining predictors or removing any of the current predictors.</p>
</div>
</div>
<div id="final-comments" class="section level3" number="9.4.2">
<h3>
<span class="header-section-number">9.4.2</span> Final comments<a class="anchor" aria-label="anchor" href="#final-comments"><i class="fas fa-link"></i></a>
</h3>
<p>We still need to check the model for regression assumptions. Also, the model chosen by these procedures are not guaranteed to be the same. The starting point, and criteria used, can also affect the model selected. Typically, automated search procedures consider models with just additive effects.</p>
<p>Use these procedures as a starting point in model building, and not as a definitive answer to choose your final model.</p>
</div>
</div>
<div id="r-tutorial-6" class="section level2" number="9.5">
<h2>
<span class="header-section-number">9.5</span> R Tutorial<a class="anchor" aria-label="anchor" href="#r-tutorial-6"><i class="fas fa-link"></i></a>
</h2>
<p>In this tutorial, we will learn how to use model selection criteria and automated search procedures in setting up our MLR model. We will be using the <code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> function from the <code>leaps</code> package to automate the process of assessing models using model selection criteria, so install and load the <code>leaps</code> package:</p>
<div class="sourceCode" id="cb344"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">leaps</span><span class="op">)</span></span></code></pre></div>
<p>We will use the <code>mtcars</code> data set that comes built in with R. The data come from 32 classic automobiles.</p>
<div class="sourceCode" id="cb345"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Data</span><span class="op">&lt;-</span><span class="va">mtcars</span></span></code></pre></div>
<p>Type <code><a href="https://rdrr.io/r/datasets/mtcars.html">?mtcars</a></code> to read the description of the data. Notice that two variables, <code>vs</code> and <code>am</code> are actually categorical and are coded using 0-1 indicators. Since they are correctly coded as 0-1 indicators, we do not need to use the <code><a href="https://rdrr.io/r/base/factor.html">factor()</a></code> function to convert these variables to be viewed as categorical.</p>
<p>When using <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>, R will perform the 0-1 coding associated with categorical variables.</p>
<p>In the examples below, we consider <code>mpg</code> to the response variable and all the other variables are potential predictors.</p>
<div id="model-selection-criteria-1" class="section level3 unnumbered">
<h3>Model Selection Criteria<a class="anchor" aria-label="anchor" href="#model-selection-criteria-1"><i class="fas fa-link"></i></a>
</h3>
<p>The <code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> function from the <code>leaps</code> package will fit all possible regression models based on the supplied dataframe and specified response variable, and then calculate the values of <span class="math inline">\(R^2\)</span>, adjusted <span class="math inline">\(R^2\)</span>, <span class="math inline">\(SS_{res}\)</span>, Mallows <span class="math inline">\(C_p\)</span>, and BIC of each model. It does not calculate the PRESS statistic and the AIC. To do so:</p>
<div class="sourceCode" id="cb346"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">allreg</span> <span class="op">&lt;-</span> <span class="fu">leaps</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets</a></span><span class="op">(</span><span class="va">mpg</span> <span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">Data</span>, nbest<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Subset selection object
## Call: regsubsets.formula(mpg ~ ., data = Data, nbest = 1)
## 10 Variables  (and intercept)
##      Forced in Forced out
## cyl      FALSE      FALSE
## disp     FALSE      FALSE
## hp       FALSE      FALSE
## drat     FALSE      FALSE
## wt       FALSE      FALSE
## qsec     FALSE      FALSE
## vs       FALSE      FALSE
## am       FALSE      FALSE
## gear     FALSE      FALSE
## carb     FALSE      FALSE
## 1 subsets of each size up to 8
## Selection Algorithm: exhaustive
##          cyl disp hp  drat wt  qsec vs  am  gear carb
## 1  ( 1 ) " " " "  " " " "  "*" " "  " " " " " "  " " 
## 2  ( 1 ) "*" " "  " " " "  "*" " "  " " " " " "  " " 
## 3  ( 1 ) " " " "  " " " "  "*" "*"  " " "*" " "  " " 
## 4  ( 1 ) " " " "  "*" " "  "*" "*"  " " "*" " "  " " 
## 5  ( 1 ) " " "*"  "*" " "  "*" "*"  " " "*" " "  " " 
## 6  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" " "  " " 
## 7  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" "*"  " " 
## 8  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" "*"  "*"</code></pre>
<p>The default value for <code>nbest</code> is 1. This means that the algorithm will return the one best set of predictors (based on <span class="math inline">\(R^2\)</span>) for each number of possible predictors.</p>
<p>So based on <span class="math inline">\(R^2\)</span>, among all possible 1-predictor models, the model that is best has <code>wt</code> as the one predictor. Among all possible 2-predictor models, the model that is best has <code>cyl</code> and <code>wt</code> as the two predictors.</p>
<p>Changing <code>nbest</code> to be 2 gives:</p>
<div class="sourceCode" id="cb348"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">allreg2</span> <span class="op">&lt;-</span> <span class="fu">leaps</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets</a></span><span class="op">(</span><span class="va">mpg</span> <span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">Data</span>, nbest<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Subset selection object
## Call: regsubsets.formula(mpg ~ ., data = Data, nbest = 2)
## 10 Variables  (and intercept)
##      Forced in Forced out
## cyl      FALSE      FALSE
## disp     FALSE      FALSE
## hp       FALSE      FALSE
## drat     FALSE      FALSE
## wt       FALSE      FALSE
## qsec     FALSE      FALSE
## vs       FALSE      FALSE
## am       FALSE      FALSE
## gear     FALSE      FALSE
## carb     FALSE      FALSE
## 2 subsets of each size up to 8
## Selection Algorithm: exhaustive
##          cyl disp hp  drat wt  qsec vs  am  gear carb
## 1  ( 1 ) " " " "  " " " "  "*" " "  " " " " " "  " " 
## 1  ( 2 ) "*" " "  " " " "  " " " "  " " " " " "  " " 
## 2  ( 1 ) "*" " "  " " " "  "*" " "  " " " " " "  " " 
## 2  ( 2 ) " " " "  "*" " "  "*" " "  " " " " " "  " " 
## 3  ( 1 ) " " " "  " " " "  "*" "*"  " " "*" " "  " " 
## 3  ( 2 ) "*" " "  "*" " "  "*" " "  " " " " " "  " " 
## 4  ( 1 ) " " " "  "*" " "  "*" "*"  " " "*" " "  " " 
## 4  ( 2 ) " " " "  " " " "  "*" "*"  " " "*" " "  "*" 
## 5  ( 1 ) " " "*"  "*" " "  "*" "*"  " " "*" " "  " " 
## 5  ( 2 ) " " " "  " " "*"  "*" "*"  " " "*" " "  "*" 
## 6  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" " "  " " 
## 6  ( 2 ) " " "*"  "*" " "  "*" "*"  " " "*" "*"  " " 
## 7  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" "*"  " " 
## 7  ( 2 ) "*" "*"  "*" "*"  "*" "*"  " " "*" " "  " " 
## 8  ( 1 ) " " "*"  "*" "*"  "*" "*"  " " "*" "*"  "*" 
## 8  ( 2 ) " " "*"  "*" "*"  "*" "*"  "*" "*" "*"  " "</code></pre>
<p>So based on <span class="math inline">\(R^2\)</span>, among all possible 1-predictor models, the model that is best has <code>wt</code> as the one predictor. The second best 1-predictor model has <code>cyl</code> as the one predictor.</p>
<p>Let’s see what can be extracted from <code>summary(allreg2)</code>:</p>
<div class="sourceCode" id="cb350"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] "which"  "rsq"    "rss"    "adjr2"  "cp"     "bic"    "outmat" "obj"</code></pre>
<p>We can extract information regarding adjusted <span class="math inline">\(R^2\)</span>, Mallow’s <span class="math inline">\(C_p\)</span>, and <span class="math inline">\(BIC\)</span>, so we can find the best models based on these criteria:</p>
<div class="sourceCode" id="cb352"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">adjr2</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 9</code></pre>
<div class="sourceCode" id="cb354"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">cp</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<div class="sourceCode" id="cb356"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">bic</span><span class="op">)</span></span></code></pre></div>
<pre><code>## [1] 5</code></pre>
<p>From <code>allreg2</code>, model 9 has the best adjusted <span class="math inline">\(R^2\)</span>, while model 5 has the best Mallow’s <span class="math inline">\(C_p\)</span> and <span class="math inline">\(BIC\)</span>. To get the corresponding coefficients and predictors of these models:</p>
<div class="sourceCode" id="cb358"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">allreg2</span>, <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.max</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">adjr2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## (Intercept)        disp          hp          wt        qsec          am 
## 14.36190396  0.01123765 -0.02117055 -4.08433206  1.00689683  3.47045340</code></pre>
<div class="sourceCode" id="cb360"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">allreg2</span>, <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">cp</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## (Intercept)          wt        qsec          am 
##    9.617781   -3.916504    1.225886    2.935837</code></pre>
<div class="sourceCode" id="cb362"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">allreg2</span>, <span class="fu"><a href="https://rdrr.io/r/base/which.min.html">which.min</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">allreg2</span><span class="op">)</span><span class="op">$</span><span class="va">bic</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code>## (Intercept)          wt        qsec          am 
##    9.617781   -3.916504    1.225886    2.935837</code></pre>
<p>It turns out we have 2 candidate models. They all have <code>wt</code>, <code>qsec</code>, and <code>am</code>. The model with the best adjusted <span class="math inline">\(R^2\)</span> has two additional predictors: <code>disp</code> and <code>hp</code>.</p>
</div>
<div id="forward-selection-backward-elimination-and-stepwise-regression" class="section level3 unnumbered">
<h3>Forward selection, backward elimination, and stepwise regression<a class="anchor" aria-label="anchor" href="#forward-selection-backward-elimination-and-stepwise-regression"><i class="fas fa-link"></i></a>
</h3>
<p>Fitting all possible regression models can be slow to run if there are many predictors and many observations. To cut down the number of potential models considered, we can use forward selection, backward elimination, and stepwise regression. These procedures will require declaring the smallest possible model, and the largest possible model first. The algorithm will consider models within this range of models.</p>
<p>To do so, we start by declaring an intercept-only model and a full model (with all predictors). These two models contain the scope of all possible models to consider:</p>
<div class="sourceCode" id="cb364"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">##intercept only model</span></span>
<span><span class="va">regnull</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">mpg</span><span class="op">~</span><span class="fl">1</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span>
<span><span class="co">##model with all predictors</span></span>
<span><span class="va">regfull</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">mpg</span><span class="op">~</span><span class="va">.</span>, data<span class="op">=</span><span class="va">Data</span><span class="op">)</span></span></code></pre></div>
<p>To carry out forward selection:</p>
<div class="sourceCode" id="cb365"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">regnull</span>, scope<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>lower<span class="op">=</span><span class="va">regnull</span>, upper<span class="op">=</span><span class="va">regfull</span><span class="op">)</span>, direction<span class="op">=</span><span class="st">"forward"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Start:  AIC=115.94
## mpg ~ 1
## 
##        Df Sum of Sq     RSS     AIC
## + wt    1    847.73  278.32  73.217
## + cyl   1    817.71  308.33  76.494
## + disp  1    808.89  317.16  77.397
## + hp    1    678.37  447.67  88.427
## + drat  1    522.48  603.57  97.988
## + vs    1    496.53  629.52  99.335
## + am    1    405.15  720.90 103.672
## + carb  1    341.78  784.27 106.369
## + gear  1    259.75  866.30 109.552
## + qsec  1    197.39  928.66 111.776
## &lt;none&gt;              1126.05 115.943
## 
## Step:  AIC=73.22
## mpg ~ wt
## 
##        Df Sum of Sq    RSS    AIC
## + cyl   1    87.150 191.17 63.198
## + hp    1    83.274 195.05 63.840
## + qsec  1    82.858 195.46 63.908
## + vs    1    54.228 224.09 68.283
## + carb  1    44.602 233.72 69.628
## + disp  1    31.639 246.68 71.356
## &lt;none&gt;              278.32 73.217
## + drat  1     9.081 269.24 74.156
## + gear  1     1.137 277.19 75.086
## + am    1     0.002 278.32 75.217
## 
## Step:  AIC=63.2
## mpg ~ wt + cyl
## 
##        Df Sum of Sq    RSS    AIC
## + hp    1   14.5514 176.62 62.665
## + carb  1   13.7724 177.40 62.805
## &lt;none&gt;              191.17 63.198
## + qsec  1   10.5674 180.60 63.378
## + gear  1    3.0281 188.14 64.687
## + disp  1    2.6796 188.49 64.746
## + vs    1    0.7059 190.47 65.080
## + am    1    0.1249 191.05 65.177
## + drat  1    0.0010 191.17 65.198
## 
## Step:  AIC=62.66
## mpg ~ wt + cyl + hp
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              176.62 62.665
## + am    1    6.6228 170.00 63.442
## + disp  1    6.1762 170.44 63.526
## + carb  1    2.5187 174.10 64.205
## + drat  1    2.2453 174.38 64.255
## + qsec  1    1.4010 175.22 64.410
## + gear  1    0.8558 175.76 64.509
## + vs    1    0.0599 176.56 64.654</code></pre>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + cyl + hp, data = Data)
## 
## Coefficients:
## (Intercept)           wt          cyl           hp  
##    38.75179     -3.16697     -0.94162     -0.01804</code></pre>
<p>At the start of the algorithm, the AIC of the intercept-only model is calculated to be 115.94. The algorithm then considers adding each predictor to the intercept-only model. For each 1-predictor model, the AIC is calculated, and the 1-predictor models are arranged from smallest to largest in terms of AIC. In the output, all 1-predictor models are superior to the intercept-only model. The predictor <code>wt</code> is chosen to be used since it results in the model with the smallest AIC.</p>
<p>In the next step, <code>wt</code> is in the model and cannot be removed. The AIC is 73.22. The algorithm then considers adding each predictor in addition to <code>wt</code>. For each two-predictor model, the AIC is calculated. The two-predictor models are then ordered from smallest to largest. Adding <code>cyl</code> leads to the smallest AIC so it is chosen to be added to <code>wt</code>. Note that adding <code>drat</code>, <code>gear</code>, or <code>am</code> to <code>wt</code> actually increases the AIC.</p>
<p>The algorithm continues until the last step. At this stage, <code>wt</code>, <code>cyl</code>, and <code>hp</code> are added to the model and have an AIC of 62.66. The algorithm considers adding one of the remaining predictors, but adding any of them results in a higher AIC. Thus the algorithm stops.</p>
<p>For backward elimination, the code is similar. The <code>direction</code> is changed from <code>forward</code> to <code>backward</code>:</p>
<div class="sourceCode" id="cb368"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">regfull</span>, scope<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>lower<span class="op">=</span><span class="va">regnull</span>, upper<span class="op">=</span><span class="va">regfull</span><span class="op">)</span>, direction<span class="op">=</span><span class="st">"backward"</span><span class="op">)</span></span></code></pre></div>
<p>And for stepwise regression, <code>direction</code> is set to <code>both</code>:</p>
<div class="sourceCode" id="cb369"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/step.html">step</a></span><span class="op">(</span><span class="va">regnull</span>, scope<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>lower<span class="op">=</span><span class="va">regnull</span>, upper<span class="op">=</span><span class="va">regfull</span><span class="op">)</span>, direction<span class="op">=</span><span class="st">"both"</span><span class="op">)</span></span></code></pre></div>
<pre><code>## Start:  AIC=115.94
## mpg ~ 1
## 
##        Df Sum of Sq     RSS     AIC
## + wt    1    847.73  278.32  73.217
## + cyl   1    817.71  308.33  76.494
## + disp  1    808.89  317.16  77.397
## + hp    1    678.37  447.67  88.427
## + drat  1    522.48  603.57  97.988
## + vs    1    496.53  629.52  99.335
## + am    1    405.15  720.90 103.672
## + carb  1    341.78  784.27 106.369
## + gear  1    259.75  866.30 109.552
## + qsec  1    197.39  928.66 111.776
## &lt;none&gt;              1126.05 115.943
## 
## Step:  AIC=73.22
## mpg ~ wt
## 
##        Df Sum of Sq     RSS     AIC
## + cyl   1     87.15  191.17  63.198
## + hp    1     83.27  195.05  63.840
## + qsec  1     82.86  195.46  63.908
## + vs    1     54.23  224.09  68.283
## + carb  1     44.60  233.72  69.628
## + disp  1     31.64  246.68  71.356
## &lt;none&gt;               278.32  73.217
## + drat  1      9.08  269.24  74.156
## + gear  1      1.14  277.19  75.086
## + am    1      0.00  278.32  75.217
## - wt    1    847.73 1126.05 115.943
## 
## Step:  AIC=63.2
## mpg ~ wt + cyl
## 
##        Df Sum of Sq    RSS    AIC
## + hp    1    14.551 176.62 62.665
## + carb  1    13.772 177.40 62.805
## &lt;none&gt;              191.17 63.198
## + qsec  1    10.567 180.60 63.378
## + gear  1     3.028 188.14 64.687
## + disp  1     2.680 188.49 64.746
## + vs    1     0.706 190.47 65.080
## + am    1     0.125 191.05 65.177
## + drat  1     0.001 191.17 65.198
## - cyl   1    87.150 278.32 73.217
## - wt    1   117.162 308.33 76.494
## 
## Step:  AIC=62.66
## mpg ~ wt + cyl + hp
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              176.62 62.665
## - hp    1    14.551 191.17 63.198
## + am    1     6.623 170.00 63.442
## + disp  1     6.176 170.44 63.526
## - cyl   1    18.427 195.05 63.840
## + carb  1     2.519 174.10 64.205
## + drat  1     2.245 174.38 64.255
## + qsec  1     1.401 175.22 64.410
## + gear  1     0.856 175.76 64.509
## + vs    1     0.060 176.56 64.654
## - wt    1   115.354 291.98 76.750</code></pre>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + cyl + hp, data = Data)
## 
## Coefficients:
## (Intercept)           wt          cyl           hp  
##    38.75179     -3.16697     -0.94162     -0.01804</code></pre>
<p>Notice with stepwise regression, we consider removing any predictor as well as adding any predictor in each step.</p>
<p>It turns out that for this dataset, forward selection, backward elimination, and stepwise regression propose the same model with <code>wt</code>, <code>cyl</code>, and <code>hp</code> as predictors.</p>
</div>
<div id="some-comments" class="section level3 unnumbered">
<h3>Some Comments<a class="anchor" aria-label="anchor" href="#some-comments"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>
<code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> and <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> functions only consider 1st order models (no interactions or higher order terms).</li>
<li>
<code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> and <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> functions do not check if the regression assumptions are met. You still need to check the residual plot.</li>
<li>
<code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> and <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> functions do not guarantee the best model will be identified for your specific goal.</li>
<li>Notice that the various model selection criteria used in <code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> can lead to different models.</li>
<li>The various procedures in the <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> function can lead to different models.</li>
<li>
<code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> function can lead to different models if you have a different starting point.</li>
<li>For the <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> function, R uses AIC to decide when to stop the search. The textbook describes the procedure using the <span class="math inline">\(F\)</span> statistic. The choice of criteria could impact the end result.</li>
</ol>
</div>
<div id="practice-question-2" class="section level3 unnumbered">
<h3>Practice Question<a class="anchor" aria-label="anchor" href="#practice-question-2"><i class="fas fa-link"></i></a>
</h3>
<p>For the candidate models found above, create residual plots and Box Cox plots to see if the response variable should be transformed. If needed, transform the response variable, and re run these the <code><a href="https://rdrr.io/pkg/leaps/man/regsubsets.html">regsubsets()</a></code> and <code><a href="https://rdrr.io/r/stats/step.html">step()</a></code> functions to see what candidate models are suggested.</p>

</div>
</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="cat.html"><span class="header-section-number">8</span> Categorical Predictors in MLR</a></div>
<div class="next"><a href="out.html"><span class="header-section-number">10</span> Analysis of Residuals in MLR</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#crit"><span class="header-section-number">9</span> Model Selection Criteria and Automated Search Procedures</a></li>
<li><a class="nav-link" href="#introduction-8"><span class="header-section-number">9.1</span> Introduction</a></li>
<li>
<a class="nav-link" href="#model-assessment-concepts"><span class="header-section-number">9.2</span> Model Assessment Concepts</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#training-and-test-data"><span class="header-section-number">9.2.1</span> Training and test data</a></li>
<li><a class="nav-link" href="#overfitting"><span class="header-section-number">9.2.2</span> Overfitting</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#model-selection-criteria"><span class="header-section-number">9.3</span> Model Selection Criteria</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#adjusted-r-squared-r_adjp2"><span class="header-section-number">9.3.1</span> Adjusted R-squared: \(R_{Adj,p}^{2}\)</a></li>
<li><a class="nav-link" href="#mallows-c_p"><span class="header-section-number">9.3.2</span> Mallow’s \(C_p\)</a></li>
<li><a class="nav-link" href="#aic_p-and-bic_p"><span class="header-section-number">9.3.3</span> \(AIC_p\) and \(BIC_p\)</a></li>
<li><a class="nav-link" href="#press-statistic"><span class="header-section-number">9.3.4</span> PRESS statistic</a></li>
<li><a class="nav-link" href="#summary-and-final-comments"><span class="header-section-number">9.3.5</span> Summary and final comments</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#automated-search-procedures"><span class="header-section-number">9.4</span> Automated Search Procedures</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#forward-selection-backward-elimination"><span class="header-section-number">9.4.1</span> Forward selection, backward elimination</a></li>
<li><a class="nav-link" href="#final-comments"><span class="header-section-number">9.4.2</span> Final comments</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#r-tutorial-6"><span class="header-section-number">9.5</span> R Tutorial</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#model-selection-criteria-1">Model Selection Criteria</a></li>
<li><a class="nav-link" href="#forward-selection-backward-elimination-and-stepwise-regression">Forward selection, backward elimination, and stepwise regression</a></li>
<li><a class="nav-link" href="#some-comments">Some Comments</a></li>
<li><a class="nav-link" href="#practice-question-2">Practice Question</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Linear Models for Data Science</strong>" was written by Jeffrey Woo. It was last built on 2024-08-02.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
